{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ui_path = \"../interim_1/nergithub.txt\"\n",
    "ugm_path = \"../interim_1/nerugm.txt\"\n",
    "\n",
    "with open(ui_path,'r') as reader:\n",
    "    ui_data = reader.read().strip().split('\\n\\n')\n",
    "\n",
    "with open(ugm_path,'r') as reader:\n",
    "    ugm_data = reader.read().strip().split('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Menurut\\tO\\nLaks\\tB-PERSON\\n,\\tO\\nstatus\\tO\\nmulti\\tO\\n-\\tO\\nlisting\\tO\\nbagi\\tO\\nTelkom\\tB-ORGANIZATION\\npenting\\tO\\ndalam\\tO\\nrangka\\tO\\nmenjaga\\tO\\ncitra\\tO\\nperseroan\\tO\\n,\\tO\\nwalaupun\\tO\\nsebetulnya\\tO\\nsaham\\tO\\nTelkom\\tB-ORGANIZATION\\nbisa\\tO\\ndiserap\\tO\\ninvestor\\tO\\nlokal\\tO\\n.\\tO',\n",
       " 'PT\\tB-ORGANIZATION\\nTelekomunikasi\\tI-ORGANIZATION\\nIndonesia\\tI-ORGANIZATION\\nTbk\\tI-ORGANIZATION\\n(\\tO\\nTelkom\\tB-ORGANIZATION\\n)\\tO\\nakan\\tO\\nmelakukan\\tO\\npembiayaan\\tO\\nkembali\\tO\\nutang\\tO\\n(\\tO\\ndebt\\tO\\nrefinancing\\tO\\n)\\tO\\ndalam\\tO\\nvaluta\\tO\\nasing\\tO\\n(\\tO\\nvalas\\tO\\n)\\tO\\n,\\tO\\nguna\\tO\\nmengurangi\\tO\\nrugi\\tO\\nvalas\\tO\\nakibat\\tO\\nfluktuasi\\tO\\nnilai\\tO\\ntukar\\tO\\n.\\tO']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ui_data[5:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_line(line):\n",
    "    splitted_line = line.split('\\n')\n",
    "    text = []\n",
    "    named_entity = {}\n",
    "    prev_bio_tag = None\n",
    "    current_named_entity = []\n",
    "    for bio_tag_token in splitted_line:\n",
    "        token, bio_tag = bio_tag_token.split('\\t')\n",
    "        text.append(token)\n",
    "\n",
    "        # 1. if bio tag is B\n",
    "        #   1.1. prev tag is None\n",
    "        #   1.2. prev tag is O\n",
    "        #   1.3. prev tag is B\n",
    "        #       1.3.1. prev tag label is same\n",
    "        #       1.3.2. prev tag label is different\n",
    "        #   1.4. prev tag is I\n",
    "        #       1.4.1. prev tag label is same\n",
    "        #       1.4.2. prev tag label is different\n",
    "        # 2. if bio tag is I\n",
    "        #   2.1. prev tag is None\n",
    "        #   2.2. prev tag is O\n",
    "        #   2.3. prev tag is B\n",
    "        #       2.3.1. prev tag label is same\n",
    "        #       2.3.2. prev tag label is different\n",
    "        #   2.4. prev tag is I\n",
    "        #       2.4.1. prev tag label is same\n",
    "        #       2.4.2. prev tag label is different\n",
    "        # 3. if bio tag is O\n",
    "        #   3.1. prev tag is None\n",
    "        #   3.2. prev tag is O\n",
    "        #   3.3. prev tag is B\n",
    "        #   3.4. prev tag is I\n",
    "        if bio_tag.startswith(\"B-\"):\n",
    "            if prev_bio_tag == None:\n",
    "                # Append token\n",
    "                current_named_entity.append(token)\n",
    "            elif prev_bio_tag == 'O':\n",
    "                # Append token\n",
    "                current_named_entity.append(token)\n",
    "            elif prev_bio_tag.startswith(\"B-\"):\n",
    "                tag_label = bio_tag[2:]\n",
    "                prev_tag_label = prev_bio_tag[2:]\n",
    "                if tag_label == prev_tag_label:\n",
    "                    if not prev_tag_label in named_entity.keys():\n",
    "                        named_entity[prev_tag_label] = []\n",
    "                    named_entity[prev_tag_label].append(' '.join(current_named_entity))\n",
    "                    current_named_entity = [token]\n",
    "                else:\n",
    "                    if not prev_tag_label in named_entity.keys():\n",
    "                        named_entity[prev_tag_label] = []\n",
    "                    named_entity[prev_tag_label].append(' '.join(current_named_entity))\n",
    "                    current_named_entity = [token]\n",
    "            elif prev_bio_tag.startswith(\"I-\"):\n",
    "                tag_label = bio_tag[2:]\n",
    "                prev_tag_label = prev_bio_tag[2:]\n",
    "                if tag_label == prev_tag_label:\n",
    "                    if not prev_tag_label in named_entity.keys():\n",
    "                        named_entity[prev_tag_label] = []\n",
    "                    named_entity[prev_tag_label].append(' '.join(current_named_entity))\n",
    "                    current_named_entity = [token]\n",
    "                else:\n",
    "                    if not prev_tag_label in named_entity.keys():\n",
    "                        named_entity[prev_tag_label] = []\n",
    "                    named_entity[prev_tag_label].append(' '.join(current_named_entity))\n",
    "                    current_named_entity = [token]\n",
    "        elif bio_tag.startswith(\"I-\"):\n",
    "            if prev_bio_tag == None:\n",
    "                raise Exception(f\"I token cannot begin a named entity phrase | line : {line}\")\n",
    "            elif prev_bio_tag == 'O':\n",
    "                raise Exception(f\"I token cannot begin a named entity phrase | line : {line}\")\n",
    "            elif prev_bio_tag.startswith(\"B-\"):\n",
    "                tag_label = bio_tag[2:]\n",
    "                prev_tag_label = prev_bio_tag[2:]\n",
    "                if tag_label == prev_tag_label:\n",
    "                    # Append token\n",
    "                    current_named_entity.append(token)\n",
    "                else:\n",
    "                    raise Exception(f\"I token cannot align with B token with different label | line : {line}\")\n",
    "            elif prev_bio_tag.startswith(\"I-\"):\n",
    "                tag_label = bio_tag[2:]\n",
    "                prev_tag_label = prev_bio_tag[2:]\n",
    "                if tag_label == prev_tag_label:\n",
    "                    # Append token\n",
    "                    current_named_entity.append(token)\n",
    "                else:\n",
    "                    raise Exception(f\"I token cannot align with I token with different label | line : {line}\")\n",
    "        elif bio_tag == 'O':\n",
    "            if prev_bio_tag == None:\n",
    "                pass\n",
    "            elif prev_bio_tag == 'O':\n",
    "                pass\n",
    "            elif prev_bio_tag.startswith(\"B-\"):\n",
    "                prev_tag_label = prev_bio_tag[2:]\n",
    "                if not prev_tag_label in named_entity.keys():\n",
    "                    named_entity[prev_tag_label] = []\n",
    "                named_entity[prev_tag_label].append(' '.join(current_named_entity))\n",
    "                current_named_entity = []\n",
    "            elif prev_bio_tag.startswith(\"I-\"):\n",
    "                prev_tag_label = prev_bio_tag[2:]\n",
    "                if not prev_tag_label in named_entity.keys():\n",
    "                    named_entity[prev_tag_label] = []\n",
    "                named_entity[prev_tag_label].append(' '.join(current_named_entity))\n",
    "                current_named_entity = []\n",
    "        prev_bio_tag = bio_tag\n",
    "    \n",
    "    if prev_bio_tag != 'O': # last token\n",
    "        prev_tag_label = prev_bio_tag[2:]\n",
    "        if not prev_tag_label in named_entity.keys():\n",
    "            named_entity[prev_tag_label] = []\n",
    "        named_entity[prev_tag_label].append(' '.join(current_named_entity))\n",
    "        current_named_entity = []\n",
    "    \n",
    "    return ' '.join(text), named_entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ui_data = [preprocess_line(line) for line in ui_data]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resolve error in ugm data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ugm_path = \"../raw/nerugm.txt\"\n",
    "with open(ugm_path,'r') as reader:\n",
    "    ugm_data = reader.read().strip().split('\\n\\n')\n",
    "\n",
    "res_ugm_data = []\n",
    "for line in ugm_data:\n",
    "    token_tag = line.split('\\n')\n",
    "    res_tokens = []\n",
    "    prev_tag = 'O'\n",
    "    for tok_tag in token_tag:\n",
    "        token, tag = tok_tag.split('\\t')\n",
    "        if prev_tag == 'O' and tag.startswith(\"I-\"):\n",
    "            tag = \"B-\" + tag[2:]\n",
    "        prev_tag = tag\n",
    "        tok_tag = token + '\\t' + tag\n",
    "        res_tokens.append(tok_tag)\n",
    "    res_ugm_data.append('\\n'.join(res_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../interim_1/nerugm.txt\",'w') as writer:\n",
    "    for line in res_ugm_data:\n",
    "        writer.write(line + '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ugm_data = [preprocess_line(line) for line in res_ugm_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Sementara itu Pengamat Pasar Modal Dandossi Matram mengatakan , sulit bagi sebuah kantor akuntan publik ( KAP ) untuk dapat menyelesaikan audit perusahaan sebesar Telkom dalam waktu 3 bulan .',\n",
       " {'PERSON': ['Dandossi Matram'],\n",
       "  'ORGANIZATION': ['kantor akuntan publik', 'KAP', 'Telkom']})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ui_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ui_data + ugm_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts = {}\n",
    "for el in data:\n",
    "    text, named_entity = el\n",
    "    for k,v in named_entity.items():\n",
    "        if k not in value_counts.keys():\n",
    "            value_counts[k] = 0\n",
    "        value_counts[k] += len(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PERSON': 3366,\n",
       " 'ORGANIZATION': 2772,\n",
       " 'LOCATION': 2256,\n",
       " 'TIME': 433,\n",
       " 'QUANTITY': 481}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Sementara itu Pengamat Pasar Modal Dandossi Matram mengatakan , sulit bagi sebuah kantor akuntan publik ( KAP ) untuk dapat menyelesaikan audit perusahaan sebesar Telkom dalam waktu 3 bulan .',\n",
       " {'PERSON': ['Dandossi Matram'],\n",
       "  'ORGANIZATION': ['kantor akuntan publik', 'KAP', 'Telkom']})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = \"<extra_id_X>\"\n",
    "data_frame = []\n",
    "for el in data:\n",
    "    text, named_entity = el\n",
    "    target = []\n",
    "    cnt = 0\n",
    "    for entity_type, entities in named_entity.items():\n",
    "        for entity in entities:\n",
    "            cnt = cnt % 100\n",
    "            entity_type = entity_type.lower()\n",
    "            target.append(mask.replace('X',str(cnt)) + ' ' + entity + ' ' + mask.replace('X',str(cnt+1)) + ' ' + entity_type)\n",
    "            cnt += 2\n",
    "    target = ' ; '.join(target)\n",
    "    target = target.strip()\n",
    "    # if len(named_entity) > 0:\n",
    "    #     chosen_named_entity = max(named_entity,key=lambda x : value_counts[x])\n",
    "    #     output = named_entity[chosen_named_entity]\n",
    "    # else:\n",
    "    #     chosen_named_entity = random.choice(list(value_counts.keys()))\n",
    "    #     output = \"NONE\"\n",
    "    # chosen_named_entity = chosen_named_entity.replace('_',' ')\n",
    "    # prompt = f\"Ekstrak seluruh entitas {chosen_named_entity} di dalam teks\"\n",
    "    # if output != \"NONE\":\n",
    "    #     output = ' , '.join(output)\n",
    "    data_frame.append({\n",
    "        \"input\" : f\"Ekstrak NER dengan format >> entity : <extra_id_0>, entity_type : <extra_id_1> | {text}\",\n",
    "        \"output\" : target\n",
    "    })\n",
    "data_frame = pd.DataFrame(data_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<extra_id_0> Dandossi Matram <extra_id_1> person ; <extra_id_2> kantor akuntan publik <extra_id_3> organization ; <extra_id_4> KAP <extra_id_5> organization ; <extra_id_6> Telkom <extra_id_7> organization'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.loc[0,\"output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame.to_csv(\"../interim_2/data.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f5045f1ed516028e6ba3c78ae58e34f2955ee8afe7e35fc1835a968676e80520"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
