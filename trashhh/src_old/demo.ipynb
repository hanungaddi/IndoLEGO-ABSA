{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import ABSADataset, NonABSADataset, Pattern, Prompter\n",
    "from model import ABSAGenerativeModelWrapper\n",
    "from training import ABSAGenerativeTrainer\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapper_config = {\n",
    "    \"model_name_or_path\" : \"t5-base\",\n",
    "    \"model_args\" : {},\n",
    "    \"tokenizer_args\" : {}\n",
    "}\n",
    "\n",
    "pattern_config = {\n",
    "    \"open_bracket\" : '(',\n",
    "    \"close_bracket\" : ')',\n",
    "    \"intra_sep\" : ',',\n",
    "    \"inter_sep\" : ';',\n",
    "    \"categories\" : [\"NONE\"]\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "Prompter masks:\n",
    "- PATTERN : Pattern mask, resulting the following example -> ( <A> , <O> , <S> )\n",
    "- CATEGORY : List of categories mask, resulting the following example -> [CAT0,CAT1]\n",
    "- IMPUTATION_FIELD : Imputation field mask, resulting the following example -> ( pizza , yummy , <S> )\n",
    "\"\"\"\n",
    "prompter_config = {\n",
    "    \"prompter_template\" : {\n",
    "        \"extraction\" : \"Extract with the format PATTERN for the following text\",\n",
    "        \"imputation\" : \"Impute the following IMPUTATION_FIELD for the following text\"\n",
    "    }\n",
    "}\n",
    "\n",
    "data_config = {\n",
    "    \"train\" : {\n",
    "        \"absa\" : {\n",
    "            \"data_path\" : \"train_triplets.txt\",\n",
    "            \"target_format\" : \"aos\"\n",
    "        },\n",
    "        \"non_absa\" : [{\n",
    "            \"data_path\" : \"non_absa.csv\"\n",
    "        }],\n",
    "        \"absa_builder_args\" : {\n",
    "            \"tasks\" : {\n",
    "                \"extraction\" : [\"as\",\"os\",'a','o'],\n",
    "                \"imputation\" : {\n",
    "                    \"aos\" : [\"ao\",\"os\"]\n",
    "                }\n",
    "            },\n",
    "            \"multiply\" : True,\n",
    "            \"shuffle\" : True,\n",
    "            \"random_state\" : 0\n",
    "        }\n",
    "    },\n",
    "    \"val\" : {\n",
    "        \"absa\" : {\n",
    "            \"data_path\" : \"eval_triplets.txt\",\n",
    "            \"target_format\" : \"aos\"\n",
    "        },\n",
    "        \"non_absa\" : [{\n",
    "            \"data_path\" : \"non_absa.csv\"\n",
    "        }],\n",
    "        \"absa_builder_args\" : {\n",
    "            \"tasks\" : {\n",
    "                \"extraction\" : [\"as\",\"os\",'a','o'],\n",
    "                \"imputation\" : {\n",
    "                    \"aos\" : [\"ao\",\"os\"]\n",
    "                }\n",
    "            },\n",
    "            \"multiply\" : True,\n",
    "            \"shuffle\" : True,\n",
    "            \"random_state\" : 0\n",
    "        }\n",
    "    },\n",
    "    \"test\" : {\n",
    "        \"absa\" : {\n",
    "            \"data_path\" : \"test_triplets.txt\",\n",
    "            \"target_format\" : \"aos\"\n",
    "        },\n",
    "        \"non_absa\" : [{\n",
    "            \"data_path\" : \"non_absa.csv\"\n",
    "        }],\n",
    "        \"task_tree\" : {\"aos\" : {\"ao\" : ['a'],\"os\" : []}}\n",
    "    }\n",
    "}\n",
    "\n",
    "encoding_args = {\n",
    "    \"max_length\" : 256,\n",
    "    \"padding\" : True,\n",
    "    \"truncation\" : True,\n",
    "    \"return_tensors\" : \"pt\"\n",
    "}\n",
    "\n",
    "train_args = {\n",
    "    \"num_train_epochs\" : 2,\n",
    "    \"learning_rate\" : 3e-4,\n",
    "    \"gradient_accumulation_steps\" : 2,\n",
    "    \"per_device_train_batch_size\" : 4,\n",
    "    \"per_device_eval_batch_size\" : 4,\n",
    "    \"save_strategy\" : \"epoch\",\n",
    "    \"evaluation_strategy\" : \"epoch\",\n",
    "    \"save_total_limit\" : 2,\n",
    "    \"metric_for_best_model\" : \"overall_f1_score\",\n",
    "    \"load_best_model_at_end\" : True,\n",
    "    \"adam_epsilon\" : 1e-8,\n",
    "    \"eval_accumulation_steps\" : 10,\n",
    "    \"output_dir\" : \"./output\",\n",
    "    \"logging_dir\" : \"./output/log_history\"\n",
    "}\n",
    "\n",
    "train_random_seed = 0\n",
    "gpu = \"0,1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapper = ABSAGenerativeModelWrapper(**wrapper_config)\n",
    "pattern = Pattern(**pattern_config)\n",
    "prompter = Prompter(**prompter_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = ABSAGenerativeTrainer(absa_model_and_tokenizer=wrapper,pattern=pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ABSA Datasets\n",
    "\n",
    "train_absa_args = data_config[\"train\"][\"absa\"]\n",
    "train_absa_args.update({\n",
    "    \"prompter\" : prompter,\n",
    "    \"prompt_side\" : wrapper.prompt_side,\n",
    "    \"pattern\" : pattern\n",
    "})\n",
    "train_absa = ABSADataset(**train_absa_args)\n",
    "\n",
    "val_absa_args = data_config[\"val\"][\"absa\"]\n",
    "val_absa_args.update({\n",
    "    \"prompter\" : prompter,\n",
    "    \"prompt_side\" : wrapper.prompt_side,\n",
    "    \"pattern\" : pattern\n",
    "})\n",
    "val_absa = ABSADataset(**val_absa_args)\n",
    "\n",
    "test_absa_args = data_config[\"test\"][\"absa\"]\n",
    "test_absa_args.update({\n",
    "    \"prompter\" : prompter,\n",
    "    \"prompt_side\" : wrapper.prompt_side,\n",
    "    \"pattern\" : pattern\n",
    "})\n",
    "test_absa = ABSADataset(**test_absa_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non ABSA Datasets\n",
    "\n",
    "non_absa_train = []\n",
    "for args in data_config[\"train\"][\"non_absa\"]:\n",
    "    args.update({\n",
    "        \"prompt_side\" : wrapper.prompt_side\n",
    "    })\n",
    "    non_absa_train.append(NonABSADataset(**args))\n",
    "\n",
    "non_absa_val = []\n",
    "for args in data_config[\"val\"][\"non_absa\"]:\n",
    "    args.update({\n",
    "        \"prompt_side\" : wrapper.prompt_side\n",
    "    })\n",
    "    non_absa_val.append(NonABSADataset(**args))\n",
    "\n",
    "non_absa_test = []\n",
    "for args in data_config[\"test\"][\"non_absa\"]:\n",
    "    args.update({\n",
    "        \"prompt_side\" : wrapper.prompt_side\n",
    "    })\n",
    "    non_absa_test.append(NonABSADataset(**args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.concat([non_absa_ds.build_data().to_pandas() for non_absa_ds in non_absa_train] + [train_absa.build_train_val_data(**data_config[\"train\"][\"absa_builder_args\"])])\n",
    "val_data = pd.concat([non_absa_ds.build_data().to_pandas() for non_absa_ds in non_absa_val] + [val_absa.build_train_val_data(**data_config[\"val\"][\"absa_builder_args\"])])\n",
    "\n",
    "train_data = Dataset.from_pandas(train_data)\n",
    "val_data = Dataset.from_pandas(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.prepare_data(train_dataset=train_data,eval_dataset=val_data, **encoding_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.compile_train_args(train_args_dict=train_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.prepare_trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train(output_dir=train_args[\"output_dir\"],random_seed=train_random_seed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoding_args = {\n",
    "    \"skip_special_tokens\" : True\n",
    "}\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_absa_preds = trainer.predict_non_absa(dataset=non_absa_test,device=device,encoding_args=encoding_args,decoding_args=decoding_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "absa_preds, summary_score = trainer.predict_absa(dataset=test_absa,task_tree=data_config[\"test\"][\"task_tree\"],device=device,encoding_args=encoding_args,decoding_args=decoding_args)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
