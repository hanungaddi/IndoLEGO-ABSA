{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import preprocess\n",
    "\n",
    "data_reader = preprocess.DataReader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"../../data/absa/id/william/train.txt\"\n",
    "val_path = \"../../data/absa/id/william/dev.txt\"\n",
    "test_path = \"../../data/absa/id/william/test.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data_reader.do(train_path)\n",
    "val = data_reader.do(val_path)\n",
    "test = data_reader.do(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def get_word_language(word):\n",
    "    try:\n",
    "        language = detect(word)\n",
    "    except:\n",
    "        # In case language detection fails, return None\n",
    "        language = None\n",
    "    return language\n",
    "\n",
    "def classify_words_by_language(text):\n",
    "    # english_words = list()\n",
    "    # indonesian_words = list()\n",
    "    result = dict()\n",
    "    \n",
    "    words = text.split()  # Tokenize text into words\n",
    "    \n",
    "    for word in tqdm(words):\n",
    "        language = get_word_language(word)\n",
    "        # if language == 'en':\n",
    "        #     english_words.append(word.lower())\n",
    "        # elif language == 'id':\n",
    "        #     indonesian_words.append(word.lower())\n",
    "        if language != None:\n",
    "            if language not in result:\n",
    "                result[language] = [word.lower()]\n",
    "            else:\n",
    "                result[language].append(word.lower())\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "text_train = []\n",
    "for el in train:\n",
    "    text = el[\"text\"]\n",
    "    text_train.append(text)\n",
    "text_train = ' '.join(text_train)\n",
    "\n",
    "# val\n",
    "text_val = []\n",
    "for el in val:\n",
    "    text = el[\"text\"]\n",
    "    text_val.append(text)\n",
    "text_val = ' '.join(text_val)\n",
    "\n",
    "# test\n",
    "text_test = []\n",
    "for el in test:\n",
    "    text = el[\"text\"]\n",
    "    text_test.append(text)\n",
    "text_test = ' '.join(text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/47734 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47734/47734 [03:58<00:00, 200.40it/s]\n",
      "100%|██████████| 15371/15371 [01:16<00:00, 200.20it/s]\n",
      "100%|██████████| 15498/15498 [01:17<00:00, 201.04it/s]\n"
     ]
    }
   ],
   "source": [
    "train_words = classify_words_by_language(text_train)\n",
    "val_words = classify_words_by_language(text_val)\n",
    "test_words = classify_words_by_language(text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N words english: 578\n",
      "N words (all): 47734\n",
      "Percentage: 0.012108769430594545\n"
     ]
    }
   ],
   "source": [
    "print(\"N words english:\", len(train_words[\"en\"]))\n",
    "print(\"N words (all):\", len(text_train.split()))\n",
    "print(\"Percentage:\", len(train_words[\"en\"])/len(text_train.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N words english: 167\n",
      "N words (all): 15371\n",
      "Percentage: 0.010864615184438228\n"
     ]
    }
   ],
   "source": [
    "print(\"N words english:\", len(val_words[\"en\"]))\n",
    "print(\"N words (all):\", len(text_val.split()))\n",
    "print(\"Percentage:\", len(val_words[\"en\"])/len(text_val.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N words english: 188\n",
      "N words (all): 15498\n",
      "Percentage: 0.012130597496451154\n"
     ]
    }
   ],
   "source": [
    "print(\"N words english:\", len(test_words[\"en\"]))\n",
    "print(\"N words (all):\", len(text_test.split()))\n",
    "print(\"Percentage:\", len(test_words[\"en\"])/len(text_test.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N words english: 115\n",
      "N words (all): 3968\n",
      "Percentage: 0.028981854838709676\n"
     ]
    }
   ],
   "source": [
    "print(\"N words english:\", len(set(train_words[\"en\"])))\n",
    "print(\"N words (all):\", len(set(text_train.split())))\n",
    "print(\"Percentage:\", len(set(train_words[\"en\"]))/len(set(text_train.split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N words english: 53\n",
      "N words (all): 2052\n",
      "Percentage: 0.025828460038986353\n"
     ]
    }
   ],
   "source": [
    "print(\"N words english:\", len(set(val_words[\"en\"])))\n",
    "print(\"N words (all):\", len(set(text_val.split())))\n",
    "print(\"Percentage:\", len(set(val_words[\"en\"]))/len(set(text_val.split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N words english: 56\n",
      "N words (all): 2042\n",
      "Percentage: 0.02742409402546523\n"
     ]
    }
   ],
   "source": [
    "print(\"N words english:\", len(set(test_words[\"en\"])))\n",
    "print(\"N words (all):\", len(set(text_test.split())))\n",
    "print(\"Percentage:\", len(set(test_words[\"en\"]))/len(set(text_test.split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
