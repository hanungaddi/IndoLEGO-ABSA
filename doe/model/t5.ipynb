{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "sys.path.append(\"../../src/\")\n",
    "import data_utils"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "peng_dir = dict(\n",
    "    lap14 = \"../../data/absa/en/peng/14lap\",\n",
    "    res14 = \"../../data/absa/en/peng/14res\",\n",
    "    res15 = \"../../data/absa/en/peng/15res\",\n",
    "    res16 = \"../../data/absa/en/peng/16res\"\n",
    ")\n",
    "\n",
    "wan_dir = dict(\n",
    "    res15 = \"../../data/absa/en/wan/interim/rest15\",\n",
    "    res16 = \"../../data/absa/en/wan/interim/rest16\"\n",
    ")\n",
    "    \n",
    "zhang_dir = dict(\n",
    "    res15 = \"../../data/absa/en/zhang/interim/interim_2/rest15\",\n",
    "    res16 = \"../../data/absa/en/zhang/interim/interim_2/rest16\"\n",
    ")\n",
    "\n",
    "william_dir = dict(\n",
    "    hotel = \"../../data/absa/id/william\"\n",
    ")\n",
    "\n",
    "peng = dict(\n",
    "    lap14 = dict(\n",
    "        train = data_utils.read_data(path=peng_dir[\"lap14\"] + \"/train_triplets.txt\",\n",
    "                                     target_format=\"aos\"),\n",
    "        val = data_utils.read_data(path=peng_dir[\"lap14\"] + \"/dev_triplets.txt\",\n",
    "                                     target_format=\"aos\"),\n",
    "        test = data_utils.read_data(path=peng_dir[\"lap14\"] + \"/test_triplets.txt\",\n",
    "                                     target_format=\"aos\")\n",
    "    ),\n",
    "    res14 = dict(\n",
    "        train = data_utils.read_data(path=peng_dir[\"res14\"] + \"/train_triplets.txt\",\n",
    "                                     target_format=\"aos\"),\n",
    "        val = data_utils.read_data(path=peng_dir[\"res14\"] + \"/dev_triplets.txt\",\n",
    "                                     target_format=\"aos\"),\n",
    "        test = data_utils.read_data(path=peng_dir[\"res14\"] + \"/test_triplets.txt\",\n",
    "                                     target_format=\"aos\")\n",
    "    ),\n",
    "    res15 = dict(\n",
    "        train = data_utils.read_data(path=peng_dir[\"res15\"] + \"/train_triplets.txt\",\n",
    "                                     target_format=\"aos\"),\n",
    "        val = data_utils.read_data(path=peng_dir[\"res15\"] + \"/dev_triplets.txt\",\n",
    "                                     target_format=\"aos\"),\n",
    "        test = data_utils.read_data(path=peng_dir[\"res15\"] + \"/test_triplets.txt\",\n",
    "                                     target_format=\"aos\")\n",
    "    ),\n",
    "    res16 = dict(\n",
    "        train = data_utils.read_data(path=peng_dir[\"res16\"] + \"/train_triplets.txt\",\n",
    "                                     target_format=\"aos\"),\n",
    "        val = data_utils.read_data(path=peng_dir[\"res16\"] + \"/dev_triplets.txt\",\n",
    "                                     target_format=\"aos\"),\n",
    "        test = data_utils.read_data(path=peng_dir[\"res16\"] + \"/test_triplets.txt\",\n",
    "                                     target_format=\"aos\")\n",
    "    )\n",
    ")\n",
    "\n",
    "wan = dict(\n",
    "    res15 = dict(\n",
    "        train = data_utils.read_data(path=wan_dir[\"res15\"] + \"/train.txt\",\n",
    "                                     target_format=\"acs\"),\n",
    "        val = data_utils.read_data(path=wan_dir[\"res15\"] + \"/dev.txt\",\n",
    "                                     target_format=\"acs\"),\n",
    "        test = data_utils.read_data(path=wan_dir[\"res15\"] + \"/test.txt\",\n",
    "                                     target_format=\"acs\")\n",
    "    ),\n",
    "    res16 = dict(\n",
    "        train = data_utils.read_data(path=wan_dir[\"res16\"] + \"/train.txt\",\n",
    "                                     target_format=\"acs\"),\n",
    "        val = data_utils.read_data(path=wan_dir[\"res16\"] + \"/dev.txt\",\n",
    "                                     target_format=\"acs\"),\n",
    "        test = data_utils.read_data(path=wan_dir[\"res16\"] + \"/test.txt\",\n",
    "                                     target_format=\"acs\")\n",
    "    )\n",
    ")\n",
    "\n",
    "zhang = dict(\n",
    "    res15 = dict(\n",
    "        train = data_utils.read_data(path=zhang_dir[\"res15\"] + \"/train.txt\",\n",
    "                                     target_format=\"acso\"),\n",
    "        val = data_utils.read_data(path=zhang_dir[\"res15\"] + \"/dev.txt\",\n",
    "                                     target_format=\"acso\"),\n",
    "        test = data_utils.read_data(path=zhang_dir[\"res15\"] + \"/test.txt\",\n",
    "                                     target_format=\"acso\")\n",
    "    ),\n",
    "    res16 = dict(\n",
    "        train = data_utils.read_data(path=zhang_dir[\"res16\"] + \"/train.txt\",\n",
    "                                     target_format=\"acso\"),\n",
    "        val = data_utils.read_data(path=zhang_dir[\"res16\"] + \"/dev.txt\",\n",
    "                                     target_format=\"acso\"),\n",
    "        test = data_utils.read_data(path=zhang_dir[\"res16\"] + \"/test.txt\",\n",
    "                                     target_format=\"acso\")\n",
    "    )\n",
    ")\n",
    "\n",
    "william = dict(\n",
    "    hotel = dict(\n",
    "        train = data_utils.read_data(path=william_dir[\"hotel\"] + \"/train.txt\",\n",
    "                                     target_format=\"aos\"),\n",
    "        val = data_utils.read_data(path=william_dir[\"hotel\"] + \"/dev.txt\",\n",
    "                                     target_format=\"aos\"),\n",
    "        test = data_utils.read_data(path=william_dir[\"hotel\"] + \"/test.txt\",\n",
    "                                     target_format=\"aos\")\n",
    "    )\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_utils.SENTIMENT_ELEMENT = {'a' : \"aspect\", 'o' : \"opinion\", 's' : \"sentiment\", 'c' : \"category\"}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. AOS (ASTE)\n",
    "    * AO\n",
    "    * AS\n",
    "    * A\n",
    "    * O\n",
    "\n",
    "2. ACS (TASD)\n",
    "    * AS\n",
    "    * CS\n",
    "    * A\n",
    "    * C\n",
    "\n",
    "3. ACOS\n",
    "    * AO\n",
    "    * AS\n",
    "    * CS\n",
    "    * A\n",
    "    * O\n",
    "    * C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['oas', 'oa', 'as', 'a', 'o', 'asc', 'sc', 'c', 'oasc']\n"
     ]
    }
   ],
   "source": [
    "task_tree = {\n",
    "    \"oas\" : [\"oa\",\"as\",'a','o'],\n",
    "    \"asc\" : [\"as\",\"sc\",'a','c'],\n",
    "    \"oasc\" : [\"oa\",\"as\",\"sc\",'a','o','c']\n",
    "}\n",
    "\n",
    "all_task = []\n",
    "for k,v1 in task_tree.items():\n",
    "    if k not in all_task:\n",
    "        all_task.append(k)\n",
    "    for v2 in v1:\n",
    "        if v2 not in all_task:\n",
    "            all_task.append(v2)\n",
    "\n",
    "print(all_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'aspect': 'battery life', 'opinion': 'good'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_utils.remove_duplicate_targets(data_utils.reduce_targets([{'aspect': 'battery life', 'opinion': 'good', \"sentiment\" : \"positive\"},{'aspect': 'battery life', 'opinion': 'good', \"sentiment\" : \"negative\"}],\"ao\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handle mix may not be a must, but we'll see it later. Will be problematic if like as (UABSA / E2E ABSA) used for training AOS (ASTE) --> may be for further experiment because we will insert imputing later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'aspect': 'battery life', 'opinion': 'good', 'sentiment': 'mixed'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_utils.handle_mix_sentiment(data_utils.reduce_targets([{'aspect': 'battery life', 'opinion': 'good', \"sentiment\" : \"positive\"},{'aspect': 'battery life', 'opinion': 'good', \"sentiment\" : \"negative\"}],\"aos\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "# Peng (ASTE/AOS)\n",
    "peng_intermediate = dict()\n",
    "\n",
    "for domain, v1 in peng.items():\n",
    "    peng_intermediate[domain] = dict()\n",
    "    for task in [\"oas\"] + task_tree[\"oas\"]:\n",
    "        peng_intermediate[domain][task] = dict()\n",
    "        for split in v1.keys():\n",
    "            ds = peng[domain][split]\n",
    "            ds_copy = deepcopy(ds)\n",
    "            for i in range(len(ds_copy)):\n",
    "                # Reduce\n",
    "                ds_copy[i][\"target\"] = data_utils.reduce_targets(ds_copy[i][\"target\"],task)\n",
    "                # Remove Duplicates\n",
    "                ds_copy[i][\"target\"] = data_utils.remove_duplicate_targets(ds_copy[i][\"target\"])\n",
    "            peng_intermediate[domain][task][split] = ds_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wan (TASD/ACS)\n",
    "wan_intermediate = dict()\n",
    "\n",
    "for domain, v1 in wan.items():\n",
    "    wan_intermediate[domain] = dict()\n",
    "    for task in [\"asc\"] + task_tree[\"asc\"]:\n",
    "        wan_intermediate[domain][task] = dict()\n",
    "        for split in v1.keys():\n",
    "            ds = wan[domain][split]\n",
    "            ds_copy = deepcopy(ds)\n",
    "            for i in range(len(ds_copy)):\n",
    "                # Reduce\n",
    "                ds_copy[i][\"target\"] = data_utils.reduce_targets(ds_copy[i][\"target\"],task)\n",
    "                # Remove Duplicates\n",
    "                ds_copy[i][\"target\"] = data_utils.remove_duplicate_targets(ds_copy[i][\"target\"])\n",
    "            wan_intermediate[domain][task][split] = ds_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zhang (ACOS)\n",
    "zhang_intermediate = dict()\n",
    "\n",
    "for domain, v1 in zhang.items():\n",
    "    zhang_intermediate[domain] = dict()\n",
    "    for task in [\"oasc\"] + task_tree[\"oasc\"]:\n",
    "        zhang_intermediate[domain][task] = dict()\n",
    "        for split in v1.keys():\n",
    "            ds = zhang[domain][split]\n",
    "            ds_copy = deepcopy(ds)\n",
    "            for i in range(len(ds_copy)):\n",
    "                # Reduce\n",
    "                ds_copy[i][\"target\"] = data_utils.reduce_targets(ds_copy[i][\"target\"],task)\n",
    "                # Remove Duplicates\n",
    "                ds_copy[i][\"target\"] = data_utils.remove_duplicate_targets(ds_copy[i][\"target\"])\n",
    "            zhang_intermediate[domain][task][split] = ds_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# William (AOS ID)\n",
    "william_intermediate = dict()\n",
    "\n",
    "for domain, v1 in william.items():\n",
    "    william_intermediate[domain] = dict()\n",
    "    for task in [\"oas\"] + task_tree[\"oas\"]:\n",
    "        william_intermediate[domain][task] = dict()\n",
    "        for split in v1.keys():\n",
    "            ds = william[domain][split]\n",
    "            ds_copy = deepcopy(ds)\n",
    "            for i in range(len(ds_copy)):\n",
    "                # Reduce\n",
    "                ds_copy[i][\"target\"] = data_utils.reduce_targets(ds_copy[i][\"target\"],task)\n",
    "                # Remove Duplicates\n",
    "                ds_copy[i][\"target\"] = data_utils.remove_duplicate_targets(ds_copy[i][\"target\"])\n",
    "            william_intermediate[domain][task][split] = ds_copy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = \"<extra_id_X>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_answer(targets,se_order):\n",
    "    result = []\n",
    "    counter = 0\n",
    "    for t in targets:\n",
    "        constructed_t = \"\"\n",
    "        for se in se_order:\n",
    "            if counter > 99:\n",
    "                raise Exception(\"Extra id more than 99!\")\n",
    "            constructed_t += ' ' + mask.replace('X',str(counter)) + ' ' + t[data_utils.SENTIMENT_ELEMENT[se]]\n",
    "            counter += 1\n",
    "        constructed_t = constructed_t.strip()\n",
    "        result.append(constructed_t)\n",
    "    result = \" ; \".join(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<extra_id_0> no <extra_id_1> GUI <extra_id_2> negative ; <extra_id_3> dark <extra_id_4> screen <extra_id_5> negative ; <extra_id_6> steady <extra_id_7> power light <extra_id_8> neutral ; <extra_id_9> steady <extra_id_10> hard drive light <extra_id_11> negative'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "construct_answer(peng_intermediate[\"lap14\"][\"oas\"][\"train\"][4][\"target\"],\"oas\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_prompt(text,se_order):\n",
    "    prompt = []\n",
    "    for counter, se in enumerate(se_order):\n",
    "        prompt.append(data_utils.SENTIMENT_ELEMENT[se] + \" : \" + mask.replace('X',str(counter)))\n",
    "    prompt = \" ,\".join(prompt)\n",
    "    result = text + \"| \" + prompt\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'One night I turned the freaking thing off after using it , the next day I turn it on , no GUI , screen all dark , power light steady , hard drive light steady and not flashing as it usually does .| opinion : <extra_id_0> ,aspect : <extra_id_1> ,sentiment : <extra_id_2>'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "construct_prompt(peng_intermediate[\"lap14\"][\"oas\"][\"train\"][4][\"text\"],\"oas\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer Catch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def catch_answer(output,se_order):\n",
    "    output = output.replace(\"<pad>\",'')\n",
    "    output = output.replace(\"</s>\",'')\n",
    "    pattern = r\"\"\n",
    "    for se in se_order:\n",
    "        if se != 's':\n",
    "            pattern += f\"<extra_id_\\d+>\\s*(?P<{data_utils.SENTIMENT_ELEMENT[se]}>[^;]+)\\s*\"\n",
    "        else:\n",
    "            pattern += f\"<extra_id_\\d+>\\s*(?P<{data_utils.SENTIMENT_ELEMENT['s']}>positive|negative|neutral)\\s*\"\n",
    "    found = [found_iter.groupdict() for found_iter in re.finditer(pattern,output)]\n",
    "    for i in range(len(found)):\n",
    "        for k, v in found[i].items():\n",
    "            found[i][k] = found[i][k].strip()\n",
    "    return found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'opinion': 'no', 'aspect': 'GUI', 'sentiment': 'negative'},\n",
       " {'opinion': 'dark', 'aspect': 'screen', 'sentiment': 'negative'},\n",
       " {'opinion': 'steady', 'aspect': 'power light', 'sentiment': 'neutral'},\n",
       " {'opinion': 'steady', 'aspect': 'hard drive light', 'sentiment': 'negative'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = construct_answer(peng_intermediate[\"lap14\"][\"oas\"][\"train\"][4][\"target\"],\"oas\")\n",
    "se_order = \"oas\"\n",
    "catch_answer(output,se_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<extra_id_0> no <extra_id_1> GUI <extra_id_2> negative ; <extra_id_3> dark <extra_id_4> screen <extra_id_5> negative ; <extra_id_6> steady <extra_id_7> power light <extra_id_8> neutral ; <extra_id_9> steady <extra_id_10> hard drive light <extra_id_11> negative'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "peng_2 = dict()\n",
    "for domain, v1 in peng_intermediate.items():\n",
    "    peng_2[domain] = {\n",
    "        \"train\" : [], # basic task\n",
    "        \"val\" : [], # complex task\n",
    "        \"test\" : [] # complex task\n",
    "    }\n",
    "    # TRAIN\n",
    "    for basic_task in task_tree[\"oas\"]:\n",
    "        for el in peng_intermediate[domain][basic_task][\"train\"]:\n",
    "            peng_2[domain][\"train\"].append({\n",
    "                    \"input\" : construct_prompt(el[\"text\"],basic_task),\n",
    "                    \"output\" : construct_answer(el[\"target\"],basic_task),\n",
    "                    \"task\" : basic_task\n",
    "                })\n",
    "    # VAL\n",
    "    for el in peng_intermediate[domain][\"oas\"][\"val\"]:\n",
    "        peng_2[domain][\"val\"].append({\n",
    "                \"input\" : construct_prompt(el[\"text\"],\"oas\"),\n",
    "                \"output\" : construct_answer(el[\"target\"],\"oas\"),\n",
    "                \"task\" : \"oas\"\n",
    "            })\n",
    "    # TEST\n",
    "    for el in peng_intermediate[domain][\"oas\"][\"test\"]:\n",
    "        peng_2[domain][\"test\"].append({\n",
    "                \"input\" : construct_prompt(el[\"text\"],\"oas\"),\n",
    "                \"output\" : construct_answer(el[\"target\"],\"oas\"),\n",
    "                \"task\" : \"oas\"\n",
    "            })\n",
    "    peng_2[domain][\"train\"] = Dataset.from_list(peng_2[domain][\"train\"])\n",
    "    peng_2[domain][\"val\"] = Dataset.from_list(peng_2[domain][\"val\"])\n",
    "    peng_2[domain][\"test\"] = Dataset.from_list(peng_2[domain][\"test\"])\n",
    "\n",
    "wan_2 = dict()\n",
    "for domain, v1 in wan_intermediate.items():\n",
    "    wan_2[domain] = {\n",
    "        \"train\" : [], # basic task\n",
    "        \"val\" : [], # complex task\n",
    "        \"test\" : [] # complex task\n",
    "    }\n",
    "    # TRAIN\n",
    "    for basic_task in task_tree[\"asc\"]:\n",
    "        for el in wan_intermediate[domain][basic_task][\"train\"]:\n",
    "            wan_2[domain][\"train\"].append({\n",
    "                    \"input\" : construct_prompt(el[\"text\"],basic_task),\n",
    "                    \"output\" : construct_answer(el[\"target\"],basic_task),\n",
    "                    \"task\" : basic_task\n",
    "                })\n",
    "    # VAL\n",
    "    for el in wan_intermediate[domain][\"asc\"][\"val\"]:\n",
    "        wan_2[domain][\"val\"].append({\n",
    "                \"input\" : construct_prompt(el[\"text\"],\"asc\"),\n",
    "                \"output\" : construct_answer(el[\"target\"],\"asc\"),\n",
    "                \"task\" : \"asc\"\n",
    "            })\n",
    "    # TEST\n",
    "    for el in wan_intermediate[domain][\"asc\"][\"test\"]:\n",
    "        wan_2[domain][\"test\"].append({\n",
    "                \"input\" : construct_prompt(el[\"text\"],\"asc\"),\n",
    "                \"output\" : construct_answer(el[\"target\"],\"asc\"),\n",
    "                \"task\" : \"asc\"\n",
    "            })\n",
    "    wan_2[domain][\"train\"] = Dataset.from_list(wan_2[domain][\"train\"])\n",
    "    wan_2[domain][\"val\"] = Dataset.from_list(wan_2[domain][\"val\"])\n",
    "    wan_2[domain][\"test\"] = Dataset.from_list(wan_2[domain][\"test\"])\n",
    "\n",
    "zhang_2 = dict()\n",
    "for domain, v1 in zhang_intermediate.items():\n",
    "    zhang_2[domain] = {\n",
    "        \"train\" : [], # basic task\n",
    "        \"val\" : [], # complex task\n",
    "        \"test\" : [] # complex task\n",
    "    }\n",
    "    # TRAIN\n",
    "    for basic_task in task_tree[\"oasc\"]:\n",
    "        for el in zhang_intermediate[domain][basic_task][\"train\"]:\n",
    "            zhang_2[domain][\"train\"].append({\n",
    "                    \"input\" : construct_prompt(el[\"text\"],basic_task),\n",
    "                    \"output\" : construct_answer(el[\"target\"],basic_task),\n",
    "                    \"task\" : basic_task\n",
    "                })\n",
    "    # VAL\n",
    "    for el in zhang_intermediate[domain][\"oasc\"][\"val\"]:\n",
    "        zhang_2[domain][\"val\"].append({\n",
    "                \"input\" : construct_prompt(el[\"text\"],\"oasc\"),\n",
    "                \"output\" : construct_answer(el[\"target\"],\"oasc\"),\n",
    "                \"task\" : \"oasc\"\n",
    "            })\n",
    "    # TEST\n",
    "    for el in zhang_intermediate[domain][\"oasc\"][\"test\"]:\n",
    "        zhang_2[domain][\"test\"].append({\n",
    "                \"input\" : construct_prompt(el[\"text\"],\"oasc\"),\n",
    "                \"output\" : construct_answer(el[\"target\"],\"oasc\"),\n",
    "                \"task\" : \"oasc\"\n",
    "            })\n",
    "    zhang_2[domain][\"train\"] = Dataset.from_list(zhang_2[domain][\"train\"])\n",
    "    zhang_2[domain][\"val\"] = Dataset.from_list(zhang_2[domain][\"val\"])\n",
    "    zhang_2[domain][\"test\"] = Dataset.from_list(zhang_2[domain][\"test\"])\n",
    "\n",
    "william_2 = dict()\n",
    "for domain, v1 in william_intermediate.items():\n",
    "    william_2[domain] = {\n",
    "        \"train\" : [], # basic task\n",
    "        \"val\" : [], # complex task\n",
    "        \"test\" : [] # complex task\n",
    "    }\n",
    "    # TRAIN\n",
    "    for basic_task in task_tree[\"oas\"]:\n",
    "        for el in william_intermediate[domain][basic_task][\"train\"]:\n",
    "            william_2[domain][\"train\"].append({\n",
    "                    \"input\" : construct_prompt(el[\"text\"],basic_task),\n",
    "                    \"output\" : construct_answer(el[\"target\"],basic_task),\n",
    "                    \"task\" : basic_task\n",
    "                })\n",
    "    # VAL\n",
    "    for el in william_intermediate[domain][\"oas\"][\"val\"]:\n",
    "        william_2[domain][\"val\"].append({\n",
    "                \"input\" : construct_prompt(el[\"text\"],\"oas\"),\n",
    "                \"output\" : construct_answer(el[\"target\"],\"oas\"),\n",
    "                \"task\" : \"oas\"\n",
    "            })\n",
    "    # TEST\n",
    "    for el in william_intermediate[domain][\"oas\"][\"test\"]:\n",
    "        william_2[domain][\"test\"].append({\n",
    "                \"input\" : construct_prompt(el[\"text\"],\"oas\"),\n",
    "                \"output\" : construct_answer(el[\"target\"],\"oas\"),\n",
    "                \"task\" : \"oas\"\n",
    "            })\n",
    "    william_2[domain][\"train\"] = Dataset.from_list(william_2[domain][\"train\"])\n",
    "    william_2[domain][\"val\"] = Dataset.from_list(william_2[domain][\"val\"])\n",
    "    william_2[domain][\"test\"] = Dataset.from_list(william_2[domain][\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'tempat yag bagus dan nyaman untuk istirahat tetapi tolong tvnya perlu di perbaiki channelnya karena banyak semutnya digambar dan water heaternya tidak bisa jadi mandi air dingin terus .| opinion : <extra_id_0> ,aspect : <extra_id_1>',\n",
       " 'output': '<extra_id_0> bagus <extra_id_1> tempat ; <extra_id_2> nyaman <extra_id_3> tempat ; <extra_id_4> perlu di perbaiki <extra_id_5> tvnya ; <extra_id_6> tidak bisa <extra_id_7> water heaternya',\n",
       " 'task': 'oa'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "william_2[\"hotel\"][\"train\"][69]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Tokenized Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/m13519061/anaconda3/envs/absa/lib/python3.9/site-packages/transformers/models/t5/tokenization_t5_fast.py:156: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer_en = AutoTokenizer.from_pretrained(\"t5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_args = {\n",
    "    \"max_length\" : 512,\n",
    "    \"padding\" : True,\n",
    "    \"truncation\" : True,\n",
    "    \"return_tensors\" : \"pt\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_en(dataset):\n",
    "    result = tokenizer_en(dataset[\"input\"], text_target=dataset[\"output\"], **encoding_args)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    }
   ],
   "source": [
    "peng_tok = dict()\n",
    "for domain, v1 in peng_2.items():\n",
    "    peng_tok[domain] = dict()\n",
    "    for split, v2 in v1.items():\n",
    "        if split != \"test\":\n",
    "            peng_tok[domain][split] = peng_2[domain][split].map(encode_en,batched=True,remove_columns=[\"input\",\"output\",\"task\"])\n",
    "        else:\n",
    "            peng_tok[domain][split] = encode_en(peng_2[domain][split])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    }
   ],
   "source": [
    "wan_tok = dict()\n",
    "for domain, v1 in wan_2.items():\n",
    "    wan_tok[domain] = dict()\n",
    "    for split, v2 in v1.items():\n",
    "        if split != \"test\":\n",
    "            wan_tok[domain][split] = wan_2[domain][split].map(encode_en,batched=True,remove_columns=[\"input\",\"output\",\"task\"])\n",
    "        else:\n",
    "            wan_tok[domain][split] = encode_en(wan_2[domain][split])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    }
   ],
   "source": [
    "zhang_tok = dict()\n",
    "for domain, v1 in zhang_2.items():\n",
    "    zhang_tok[domain] = dict()\n",
    "    for split, v2 in v1.items():\n",
    "        if split != \"test\":\n",
    "            zhang_tok[domain][split] = zhang_2[domain][split].map(encode_en,batched=True,remove_columns=[\"input\",\"output\",\"task\"])\n",
    "        else:\n",
    "            zhang_tok[domain][split] = encode_en(zhang_2[domain][split])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_id = AutoTokenizer.from_pretrained(\"Wikidepia/IndoT5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_id(dataset):\n",
    "    result = tokenizer_id(dataset[\"input\"], text_target=dataset[\"output\"], **encoding_args)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    }
   ],
   "source": [
    "william_tok = dict()\n",
    "for domain, v1 in william_2.items():\n",
    "    william_tok[domain] = dict()\n",
    "    for split, v2 in v1.items():\n",
    "        if split != \"test\":\n",
    "            william_tok[domain][split] = william_2[domain][split].map(encode_id,batched=True,remove_columns=[\"input\",\"output\",\"task\"])\n",
    "        else:\n",
    "            william_tok[domain][split] = encode_id(william_2[domain][split])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collator"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator_en = DataCollatorForSeq2Seq(tokenizer=tokenizer_en)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator_id = DataCollatorForSeq2Seq(tokenizer=tokenizer_id)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import EvalPrediction\n",
    "from evaluation import recall, precision, f1_score, summary_score\n",
    "from typing import List, Dict, Tuple\n",
    "import numpy as np\n",
    "\n",
    "def seperate_target_prediction_per_task(predictions:List[List[Dict]],targets:List[List[Dict]],tasks:List) -> Tuple[Dict[str,List],Dict[str,List]]:\n",
    "    per_task_targets = {}\n",
    "    per_task_predictions = {}\n",
    "    for target, prediction, task in zip(targets,predictions,tasks):\n",
    "        if task not in per_task_targets.keys():\n",
    "            per_task_targets[task] = []\n",
    "        if task not in per_task_predictions.keys():\n",
    "            per_task_predictions[task] = []\n",
    "        per_task_targets[task].append(target)\n",
    "        per_task_predictions[task].append(prediction)\n",
    "    return per_task_targets, per_task_predictions\n",
    "\n",
    "def preprocess_eval_preds(eval_preds:EvalPrediction,decoding_args:Dict[str,str],tokenizer:AutoTokenizer):\n",
    "    input_ids = eval_preds.inputs\n",
    "    target_ids = eval_preds.label_ids\n",
    "    pred_ids = eval_preds.predictions\n",
    "\n",
    "    # In case the model returns more than the prediction logits\n",
    "    if isinstance(input_ids, tuple):\n",
    "        input_ids = input_ids[0]\n",
    "    if isinstance(target_ids, tuple):\n",
    "        target_ids = target_ids[0]\n",
    "    if isinstance(pred_ids, tuple):\n",
    "        pred_ids = pred_ids[0]\n",
    "    \n",
    "    input_ids = np.argmax(input_ids,axis=-1) if len(input_ids.shape) == 3 else input_ids # in case not predict with generate\n",
    "    target_ids = np.argmax(target_ids,axis=-1) if len(target_ids.shape) == 3 else target_ids # in case not predict with generate\n",
    "    prediction_ids = np.argmax(pred_ids,axis=-1) if len(pred_ids.shape) == 3 else pred_ids # in case not predict with generate\n",
    "\n",
    "    input_ids = [[token for token in row if token != -100] for row in input_ids]\n",
    "    target_ids = [[token for token in row if token != -100] for row in target_ids]\n",
    "    prediction_ids = [[token for token in row if token != -100] for row in prediction_ids]\n",
    "\n",
    "    inputs = tokenizer.batch_decode(input_ids,**decoding_args)\n",
    "    targets = tokenizer.batch_decode(target_ids,**decoding_args)\n",
    "    predictions = tokenizer.batch_decode(prediction_ids,**decoding_args)\n",
    "\n",
    "    return inputs, targets, predictions\n",
    "\n",
    "def compute_metrics(eval_preds:EvalPrediction,decoding_args:Dict[str,str],tokenizer:AutoTokenizer,tasks:List) -> Dict[str,float]: # MAY NOT BE SUFFICIATE FOR CAUSAL LM\n",
    "        \"\"\"\n",
    "        ### DESC\n",
    "            Method to compute the metrics.\n",
    "        ### PARAMS\n",
    "        * eval_preds: EvalPrediction instance from training.\n",
    "        * decoding_args: Decoding arguments.\n",
    "        ### RETURN\n",
    "        * metrics: Dictionary of metrics.\n",
    "        \"\"\"\n",
    "        inputs, targets, predictions = preprocess_eval_preds(eval_preds,decoding_args,tokenizer)\n",
    "\n",
    "        targets = [catch_answer(text,task) for text,task in zip(targets,tasks) if task != \"non_absa\"]\n",
    "        predictions = [catch_answer(text,task) for text,task in zip(predictions,tasks) if task != \"non_absa\"]\n",
    "\n",
    "\n",
    "        per_task_targets, per_task_predictions = seperate_target_prediction_per_task(predictions, targets, tasks)\n",
    "        \n",
    "        metrics = {}\n",
    "\n",
    "        metrics[\"overall_recall\"] = recall(predictions,targets)\n",
    "        metrics[\"overall_precision\"] = precision(predictions,targets)\n",
    "        metrics[\"overall_f1_score\"] = f1_score(predictions,targets)\n",
    "\n",
    "        for task in per_task_targets.keys():\n",
    "            if task == \"non_absa\":\n",
    "                continue\n",
    "            metrics[f\"{task}_recall\"] = recall(per_task_predictions[task],per_task_targets[task])\n",
    "            metrics[f\"{task}_precision\"] = precision(per_task_predictions[task],per_task_targets[task])\n",
    "            metrics[f\"{task}_f1_score\"] = f1_score(per_task_predictions[task],per_task_targets[task])\n",
    "        \n",
    "        return metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "train_args = {\n",
    "    \"num_train_epochs\": 20,\n",
    "    \"learning_rate\": 3e-4,\n",
    "    \"save_total_limit\": 2,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"per_device_train_batch_size\": 32,\n",
    "    \"per_device_eval_batch_size\": 32,\n",
    "    \"save_strategy\": \"epoch\",\n",
    "    \"evaluation_strategy\": \"epoch\",\n",
    "    \"logging_strategy\" : \"epoch\",\n",
    "    \"metric_for_best_model\": \"overall_f1_score\",\n",
    "    \"load_best_model_at_end\": True,\n",
    "    \"adam_epsilon\": 1e-08,\n",
    "    \"output_dir\": \"./t5\",\n",
    "    \"logging_dir\" : \"./t5/log\",\n",
    "    \"include_inputs_for_metrics\" : True\n",
    "}\n",
    "\n",
    "train_args = Seq2SeqTrainingArguments(**train_args)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_en = AutoModelForSeq2SeqLM.from_pretrained(\"t5-base\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = AutoModelForSeq2SeqLM.from_pretrained(\"Wikidepia/IndoT5-base\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainer\n",
    "\n",
    "trainer = {\n",
    "    \"peng\" : {},\n",
    "    \"wan\" : {},\n",
    "    \"zhang\" : {},\n",
    "    \"william\" : {}\n",
    "}\n",
    "\n",
    "decoding_args = {\n",
    "    \"skip_special_tokens\" : False\n",
    "}\n",
    "\n",
    "def preprocess_logits_for_metrics(logits, labels):\n",
    "    pred_logits = logits[0] if isinstance(logits,tuple) else logits\n",
    "    pred_ids = torch.argmax(pred_logits, dim=-1)\n",
    "    return pred_ids, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def generate_predictions(model,tokenizer,tokenized:torch.Tensor,device:torch.device=torch.device(\"cpu\"),batch_size:int=16,max_len:int=512,decoding_args:Dict={}) -> List[str]:\n",
    "    # Data loader\n",
    "    input_ids_data_loader = torch.utils.data.DataLoader(tokenized[\"input_ids\"],\n",
    "                        batch_size=batch_size,shuffle=False)\n",
    "    attention_mask_data_loader = torch.utils.data.DataLoader(tokenized[\"attention_mask\"],\n",
    "                        batch_size=batch_size,shuffle=False)\n",
    "    # Predict\n",
    "    model = model\n",
    "    tokenizer = tokenizer\n",
    "    tensor_predictions = []\n",
    "    with torch.no_grad():\n",
    "        for input_ids, attention_mask in tqdm(zip(input_ids_data_loader,attention_mask_data_loader)):\n",
    "            input_ids = input_ids.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "            tensor_predictions.extend(model.generate(input_ids=input_ids,attention_mask=attention_mask,max_length=max_len,pad_token_id=tokenizer.pad_token_id,eos_token_id=tokenizer.eos_token_id).cpu())\n",
    "            input_ids = input_ids.cpu()\n",
    "            attention_mask = attention_mask.cpu()\n",
    "    tensor_predictions = [[token for token in row if token != -100] for row in tensor_predictions]\n",
    "    predictions = tokenizer.batch_decode(tensor_predictions,**decoding_args)\n",
    "    return predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peng Laptop 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/m13519061/anaconda3/envs/absa/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 3624\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2280\n",
      "  Number of trainable parameters = 222903552\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='184' max='2280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 184/2280 01:08 < 13:11, 2.65 it/s, Epoch 1.61/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Overall Recall</th>\n",
       "      <th>Overall Precision</th>\n",
       "      <th>Overall F1 Score</th>\n",
       "      <th>Oas Recall</th>\n",
       "      <th>Oas Precision</th>\n",
       "      <th>Oas F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.530700</td>\n",
       "      <td>0.164901</td>\n",
       "      <td>0.321739</td>\n",
       "      <td>0.452000</td>\n",
       "      <td>0.375905</td>\n",
       "      <td>0.321739</td>\n",
       "      <td>0.452000</td>\n",
       "      <td>0.375905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 219\n",
      "  Batch size = 32\n",
      "  Num examples = 219\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-114\n",
      "Configuration saved in ./t5/checkpoint-114/config.json\n",
      "Saving model checkpoint to ./t5/checkpoint-114\n",
      "Configuration saved in ./t5/checkpoint-114/config.json\n",
      "Model weights saved in ./t5/checkpoint-114/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-114/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-114/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-114/spiece.model\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 219\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-228\n",
      "Configuration saved in ./t5/checkpoint-228/config.json\n",
      "Model weights saved in ./t5/checkpoint-228/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-228/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-228/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-228/spiece.model\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 219\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-342\n",
      "Configuration saved in ./t5/checkpoint-342/config.json\n",
      "Model weights saved in ./t5/checkpoint-342/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-342/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-342/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-342/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-114] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 219\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-456\n",
      "Configuration saved in ./t5/checkpoint-456/config.json\n",
      "Model weights saved in ./t5/checkpoint-456/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-456/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-456/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-456/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-228] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 219\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-570\n",
      "Configuration saved in ./t5/checkpoint-570/config.json\n",
      "Model weights saved in ./t5/checkpoint-570/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-570/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-570/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-570/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-342] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 219\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-684\n",
      "Configuration saved in ./t5/checkpoint-684/config.json\n",
      "Model weights saved in ./t5/checkpoint-684/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-684/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-684/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-684/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-456] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 219\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-798\n",
      "Configuration saved in ./t5/checkpoint-798/config.json\n",
      "Model weights saved in ./t5/checkpoint-798/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-798/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-798/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-798/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-570] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 219\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-912\n",
      "Configuration saved in ./t5/checkpoint-912/config.json\n",
      "Model weights saved in ./t5/checkpoint-912/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-912/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-912/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-912/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-798] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 219\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-1026\n",
      "Configuration saved in ./t5/checkpoint-1026/config.json\n",
      "Model weights saved in ./t5/checkpoint-1026/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-1026/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-1026/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-1026/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-912] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 219\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-1140\n",
      "Configuration saved in ./t5/checkpoint-1140/config.json\n",
      "Model weights saved in ./t5/checkpoint-1140/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-1140/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-1140/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-1140/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-1026] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 219\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-1254\n",
      "Configuration saved in ./t5/checkpoint-1254/config.json\n",
      "Model weights saved in ./t5/checkpoint-1254/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-1254/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-1254/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-1254/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-1140] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 219\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-1368\n",
      "Configuration saved in ./t5/checkpoint-1368/config.json\n",
      "Model weights saved in ./t5/checkpoint-1368/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-1368/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-1368/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-1368/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-1254] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 219\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-1482\n",
      "Configuration saved in ./t5/checkpoint-1482/config.json\n",
      "Model weights saved in ./t5/checkpoint-1482/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-1482/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-1482/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-1482/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-1368] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 219\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-1596\n",
      "Configuration saved in ./t5/checkpoint-1596/config.json\n",
      "Model weights saved in ./t5/checkpoint-1596/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-1596/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-1596/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-1596/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-684] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 219\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-1710\n",
      "Configuration saved in ./t5/checkpoint-1710/config.json\n",
      "Model weights saved in ./t5/checkpoint-1710/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-1710/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-1710/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-1710/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-1482] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 219\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-1824\n",
      "Configuration saved in ./t5/checkpoint-1824/config.json\n",
      "Model weights saved in ./t5/checkpoint-1824/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-1824/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-1824/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-1824/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-1710] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 219\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-1938\n",
      "Configuration saved in ./t5/checkpoint-1938/config.json\n",
      "Model weights saved in ./t5/checkpoint-1938/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-1938/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-1938/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-1938/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-1824] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 219\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-2052\n",
      "Configuration saved in ./t5/checkpoint-2052/config.json\n",
      "Model weights saved in ./t5/checkpoint-2052/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-2052/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-2052/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-2052/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-1938] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 219\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-2166\n",
      "Configuration saved in ./t5/checkpoint-2166/config.json\n",
      "Model weights saved in ./t5/checkpoint-2166/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-2166/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-2166/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-2166/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-2052] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 219\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-2280\n",
      "Configuration saved in ./t5/checkpoint-2280/config.json\n",
      "Model weights saved in ./t5/checkpoint-2280/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-2280/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-2280/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-2280/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-2166] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./t5/checkpoint-1596 (score: 0.5613128311151312).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2280, training_loss=0.03503607097817095, metrics={'train_runtime': 901.4619, 'train_samples_per_second': 80.403, 'train_steps_per_second': 2.529, 'total_flos': 8965382543769600.0, 'train_loss': 0.03503607097817095, 'epoch': 20.0})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_en = AutoModelForSeq2SeqLM.from_pretrained(\"t5-base\")\n",
    "model_en.to(device)\n",
    "trainer[\"peng\"][\"lap14\"] = Seq2SeqTrainer(\n",
    "        model = model_en,\n",
    "        args = train_args,\n",
    "        tokenizer = tokenizer_en,\n",
    "        data_collator = data_collator_en,\n",
    "        train_dataset = peng_tok[\"lap14\"][\"train\"],\n",
    "        eval_dataset = peng_tok[\"lap14\"][\"val\"],\n",
    "        compute_metrics = lambda eval_preds: compute_metrics(eval_preds,decoding_args,tokenizer_en,peng_2[\"lap14\"][\"val\"][\"task\"]),\n",
    "        preprocess_logits_for_metrics = preprocess_logits_for_metrics\n",
    "    )\n",
    "\n",
    "trainer[\"peng\"][\"lap14\"].train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:06,  1.71it/s]\n"
     ]
    }
   ],
   "source": [
    "str_preds = generate_predictions(model_en, tokenizer_en, peng_tok[\"lap14\"][\"test\"], device, 32, 512, decoding_args)\n",
    "preds = [catch_answer(el,\"oas\") for el in str_preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [catch_answer(el,\"oas\") for el in peng_2[\"lap14\"][\"test\"][\"output\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recall': 0.5027726432532348,\n",
       " 'precision': 0.6570048309178744,\n",
       " 'f1_score': 0.5696335078534032}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_score(preds,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!rm -rf ./t5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "numba_device = cuda.get_current_device()\n",
    "numba_device.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peng Restaurant 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/m13519061/.cache/huggingface/hub/models--t5-base/snapshots/fe6d9bf207cd3337512ca838a8b453f87a9178ef/config.json\n",
      "Model config T5Config {\n",
      "  \"_name_or_path\": \"t5-base\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 3072,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/m13519061/.cache/huggingface/hub/models--t5-base/snapshots/fe6d9bf207cd3337512ca838a8b453f87a9178ef/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
      "\n",
      "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at t5-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: invalid argument\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model_en \u001b[39m=\u001b[39m AutoModelForSeq2SeqLM\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39mt5-base\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m model_en\u001b[39m.\u001b[39;49mto(device)\n\u001b[1;32m      3\u001b[0m trainer[\u001b[39m\"\u001b[39m\u001b[39mpeng\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mres14\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m Seq2SeqTrainer(\n\u001b[1;32m      4\u001b[0m         model \u001b[39m=\u001b[39m model_en,\n\u001b[1;32m      5\u001b[0m         args \u001b[39m=\u001b[39m train_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m         preprocess_logits_for_metrics \u001b[39m=\u001b[39m preprocess_logits_for_metrics\n\u001b[1;32m     12\u001b[0m     )\n\u001b[1;32m     14\u001b[0m trainer[\u001b[39m\"\u001b[39m\u001b[39mpeng\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mres14\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mtrain()\n",
      "File \u001b[0;32m~/anaconda3/envs/absa/lib/python3.9/site-packages/torch/nn/modules/module.py:989\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    985\u001b[0m         \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    986\u001b[0m                     non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[1;32m    987\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m--> 989\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(convert)\n",
      "File \u001b[0;32m~/anaconda3/envs/absa/lib/python3.9/site-packages/torch/nn/modules/module.py:641\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    640\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 641\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    643\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    644\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    645\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    646\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    651\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    652\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/absa/lib/python3.9/site-packages/torch/nn/modules/module.py:664\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    661\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    662\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    663\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 664\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[1;32m    665\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    666\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/anaconda3/envs/absa/lib/python3.9/site-packages/torch/nn/modules/module.py:987\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    984\u001b[0m \u001b[39mif\u001b[39;00m convert_to_format \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m t\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m):\n\u001b[1;32m    985\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    986\u001b[0m                 non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[0;32m--> 987\u001b[0m \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39;49mto(device, dtype \u001b[39mif\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_floating_point() \u001b[39mor\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_complex() \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, non_blocking)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: invalid argument\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "model_en = AutoModelForSeq2SeqLM.from_pretrained(\"t5-base\")\n",
    "model_en.to(device)\n",
    "trainer[\"peng\"][\"res14\"] = Seq2SeqTrainer(\n",
    "        model = model_en,\n",
    "        args = train_args,\n",
    "        tokenizer = tokenizer_en,\n",
    "        data_collator = data_collator_en,\n",
    "        train_dataset = peng_tok[\"res14\"][\"train\"],\n",
    "        eval_dataset = peng_tok[\"res14\"][\"val\"],\n",
    "        compute_metrics = lambda eval_preds: compute_metrics(eval_preds,decoding_args,tokenizer_en,peng_2[\"res14\"][\"val\"][\"task\"]),\n",
    "        preprocess_logits_for_metrics = preprocess_logits_for_metrics\n",
    "    )\n",
    "\n",
    "trainer[\"peng\"][\"res14\"].train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [00:17,  1.11s/it]\n"
     ]
    }
   ],
   "source": [
    "str_preds = generate_predictions(model_en, tokenizer_en, peng_tok[\"res14\"][\"test\"], device, 32, 512, decoding_args)\n",
    "preds = [catch_answer(el,\"oas\") for el in str_preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [catch_answer(el,\"oas\") for el in peng_2[\"res14\"][\"test\"][\"output\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recall': 0.4305835010060362,\n",
       " 'precision': 0.7210084033613445,\n",
       " 'f1_score': 0.5391742012021976}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_score(preds,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!rm -rf ./t5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numba_device = cuda.get_current_device()\n",
    "numba_device.reset()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peng Restaurant 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/m13519061/.cache/huggingface/hub/models--t5-base/snapshots/fe6d9bf207cd3337512ca838a8b453f87a9178ef/config.json\n",
      "Model config T5Config {\n",
      "  \"_name_or_path\": \"t5-base\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 3072,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/m13519061/.cache/huggingface/hub/models--t5-base/snapshots/fe6d9bf207cd3337512ca838a8b453f87a9178ef/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
      "\n",
      "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at t5-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n",
      "/home/m13519061/anaconda3/envs/absa/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2420\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1520\n",
      "  Number of trainable parameters = 222903552\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='1520' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  31/1520 00:13 < 11:14, 2.21 it/s, Epoch 0.39/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1520, training_loss=0.03920878225104197, metrics={'train_runtime': 763.4677, 'train_samples_per_second': 63.395, 'train_steps_per_second': 1.991, 'total_flos': 7138128273408000.0, 'train_loss': 0.03920878225104197, 'epoch': 20.0})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_en = AutoModelForSeq2SeqLM.from_pretrained(\"t5-base\")\n",
    "model_en.to(device)\n",
    "trainer[\"peng\"][\"res15\"] = Seq2SeqTrainer(\n",
    "        model = model_en,\n",
    "        args = train_args,\n",
    "        tokenizer = tokenizer_en,\n",
    "        data_collator = data_collator_en,\n",
    "        train_dataset = peng_tok[\"res15\"][\"train\"],\n",
    "        eval_dataset = peng_tok[\"res15\"][\"val\"],\n",
    "        compute_metrics = lambda eval_preds: compute_metrics(eval_preds,decoding_args,tokenizer_en,peng_2[\"res15\"][\"val\"][\"task\"]),\n",
    "        preprocess_logits_for_metrics = preprocess_logits_for_metrics\n",
    "    )\n",
    "\n",
    "trainer[\"peng\"][\"res15\"].train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:09,  1.11it/s]\n"
     ]
    }
   ],
   "source": [
    "str_preds = generate_predictions(model_en, tokenizer_en, peng_tok[\"res15\"][\"test\"], device, 32, 512, decoding_args)\n",
    "preds = [catch_answer(el,\"oas\") for el in str_preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [catch_answer(el,\"oas\") for el in peng_2[\"res15\"][\"test\"][\"output\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recall': 0.5298969072164949,\n",
       " 'precision': 0.6277372262773723,\n",
       " 'f1_score': 0.5746824581702831}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_score(preds,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!rm -rf ./t5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numba_device = cuda.get_current_device()\n",
    "numba_device.reset()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peng Restaurant 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/m13519061/.cache/huggingface/hub/models--t5-base/snapshots/fe6d9bf207cd3337512ca838a8b453f87a9178ef/config.json\n",
      "Model config T5Config {\n",
      "  \"_name_or_path\": \"t5-base\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 3072,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/m13519061/.cache/huggingface/hub/models--t5-base/snapshots/fe6d9bf207cd3337512ca838a8b453f87a9178ef/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
      "\n",
      "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at t5-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n",
      "/home/m13519061/anaconda3/envs/absa/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 3428\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2160\n",
      "  Number of trainable parameters = 222903552\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='325' max='2160' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 325/2160 02:27 < 13:56, 2.19 it/s, Epoch 3/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Overall Recall</th>\n",
       "      <th>Overall Precision</th>\n",
       "      <th>Overall F1 Score</th>\n",
       "      <th>Oas Recall</th>\n",
       "      <th>Oas Precision</th>\n",
       "      <th>Oas F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.504400</td>\n",
       "      <td>0.088252</td>\n",
       "      <td>0.575221</td>\n",
       "      <td>0.655518</td>\n",
       "      <td>0.612750</td>\n",
       "      <td>0.575221</td>\n",
       "      <td>0.655518</td>\n",
       "      <td>0.612750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.032200</td>\n",
       "      <td>0.083801</td>\n",
       "      <td>0.613569</td>\n",
       "      <td>0.726644</td>\n",
       "      <td>0.665336</td>\n",
       "      <td>0.613569</td>\n",
       "      <td>0.726644</td>\n",
       "      <td>0.665336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/7 00:00 < 00:00, 9.29 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 210\n",
      "  Num examples = 210\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-108\n",
      "Configuration saved in ./t5/checkpoint-108/config.json\n",
      "Saving model checkpoint to ./t5/checkpoint-108\n",
      "Configuration saved in ./t5/checkpoint-108/config.json\n",
      "Model weights saved in ./t5/checkpoint-108/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-108/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-108/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-108/spiece.model\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 210\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 210\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-216\n",
      "Configuration saved in ./t5/checkpoint-216/config.json\n",
      "Saving model checkpoint to ./t5/checkpoint-216\n",
      "Configuration saved in ./t5/checkpoint-216/config.json\n",
      "Model weights saved in ./t5/checkpoint-216/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-216/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-216/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-216/spiece.model\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 210\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 210\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-324\n",
      "Configuration saved in ./t5/checkpoint-324/config.json\n",
      "Model weights saved in ./t5/checkpoint-324/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-324/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-324/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-324/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-108] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 210\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-432\n",
      "Configuration saved in ./t5/checkpoint-432/config.json\n",
      "Model weights saved in ./t5/checkpoint-432/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-432/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-432/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-432/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-324] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 210\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-540\n",
      "Configuration saved in ./t5/checkpoint-540/config.json\n",
      "Model weights saved in ./t5/checkpoint-540/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-540/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-540/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-540/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-216] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 210\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-648\n",
      "Configuration saved in ./t5/checkpoint-648/config.json\n",
      "Model weights saved in ./t5/checkpoint-648/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-648/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-648/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-648/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-432] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 210\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-756\n",
      "Configuration saved in ./t5/checkpoint-756/config.json\n",
      "Model weights saved in ./t5/checkpoint-756/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-756/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-756/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-756/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-648] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 210\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-864\n",
      "Configuration saved in ./t5/checkpoint-864/config.json\n",
      "Model weights saved in ./t5/checkpoint-864/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-864/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-864/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-864/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-540] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 210\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-972\n",
      "Configuration saved in ./t5/checkpoint-972/config.json\n",
      "Model weights saved in ./t5/checkpoint-972/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-972/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-972/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-972/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-756] due to args.save_total_limit\n",
      "Saving model checkpoint to ./t5/checkpoint-1080\n",
      "Configuration saved in ./t5/checkpoint-1080/config.json\n",
      "Model weights saved in ./t5/checkpoint-1080/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-1080/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-1080/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-1080/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-972] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 210\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-1188\n",
      "Configuration saved in ./t5/checkpoint-1188/config.json\n",
      "Model weights saved in ./t5/checkpoint-1188/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-1188/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-1188/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-1188/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-1080] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 210\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-1296\n",
      "Configuration saved in ./t5/checkpoint-1296/config.json\n",
      "Model weights saved in ./t5/checkpoint-1296/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-1296/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-1296/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-1296/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-1188] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 210\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-1404\n",
      "Configuration saved in ./t5/checkpoint-1404/config.json\n",
      "Model weights saved in ./t5/checkpoint-1404/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-1404/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-1404/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-1404/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-1296] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 210\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-1512\n",
      "Configuration saved in ./t5/checkpoint-1512/config.json\n",
      "Model weights saved in ./t5/checkpoint-1512/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-1512/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-1512/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-1512/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-1404] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 210\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-1620\n",
      "Configuration saved in ./t5/checkpoint-1620/config.json\n",
      "Model weights saved in ./t5/checkpoint-1620/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-1620/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-1620/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-1620/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-1512] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 210\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-1728\n",
      "Configuration saved in ./t5/checkpoint-1728/config.json\n",
      "Model weights saved in ./t5/checkpoint-1728/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-1728/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-1728/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-1728/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-1620] due to args.save_total_limit\n",
      "Saving model checkpoint to ./t5/checkpoint-1836\n",
      "Configuration saved in ./t5/checkpoint-1836/config.json\n",
      "Model weights saved in ./t5/checkpoint-1836/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-1836/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-1836/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-1836/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-1728] due to args.save_total_limit\n",
      "Saving model checkpoint to ./t5/checkpoint-1944\n",
      "Configuration saved in ./t5/checkpoint-1944/config.json\n",
      "Model weights saved in ./t5/checkpoint-1944/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-1944/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-1944/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-1944/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-1836] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 210\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-2052\n",
      "Configuration saved in ./t5/checkpoint-2052/config.json\n",
      "Model weights saved in ./t5/checkpoint-2052/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-2052/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-2052/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-2052/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-1944] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 210\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-2160\n",
      "Configuration saved in ./t5/checkpoint-2160/config.json\n",
      "Model weights saved in ./t5/checkpoint-2160/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-2160/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-2160/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-2160/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-2052] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./t5/checkpoint-864 (score: 0.7025614218504966).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2160, training_loss=0.030442173609992972, metrics={'train_runtime': 1022.3089, 'train_samples_per_second': 67.064, 'train_steps_per_second': 2.113, 'total_flos': 1.011127478188032e+16, 'train_loss': 0.030442173609992972, 'epoch': 20.0})"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_en = AutoModelForSeq2SeqLM.from_pretrained(\"t5-base\")\n",
    "model_en.to(device)\n",
    "trainer[\"peng\"][\"res16\"] = Seq2SeqTrainer(\n",
    "        model = model_en,\n",
    "        args = train_args,\n",
    "        tokenizer = tokenizer_en,\n",
    "        data_collator = data_collator_en,\n",
    "        train_dataset = peng_tok[\"res16\"][\"train\"],\n",
    "        eval_dataset = peng_tok[\"res16\"][\"val\"],\n",
    "        compute_metrics = lambda eval_preds: compute_metrics(eval_preds,decoding_args,tokenizer_en,peng_2[\"res16\"][\"val\"][\"task\"]),\n",
    "        preprocess_logits_for_metrics = preprocess_logits_for_metrics\n",
    "    )\n",
    "\n",
    "trainer[\"peng\"][\"res16\"].train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:11,  1.05s/it]\n"
     ]
    }
   ],
   "source": [
    "str_preds = generate_predictions(model_en, tokenizer_en, peng_tok[\"res16\"][\"test\"], device, 32, 512, decoding_args)\n",
    "preds = [catch_answer(el,\"oas\") for el in str_preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [catch_answer(el,\"oas\") for el in peng_2[\"res16\"][\"test\"][\"output\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recall': 0.603112840466926,\n",
       " 'precision': 0.6813186813186813,\n",
       " 'f1_score': 0.6398348813209495}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_score(preds,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!rm -rf ./t5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numba_device = cuda.get_current_device()\n",
    "numba_device.reset()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wan Restaurant 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/m13519061/anaconda3/envs/absa/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 5600\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3500\n",
      "  Number of trainable parameters = 222903552\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='176' max='3500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 176/3500 01:18 < 25:02, 2.21 it/s, Epoch 1/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 10\n",
      "  Batch size = 32\n",
      "  Num examples = 10\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-175\n",
      "Saving model checkpoint to ./t5/checkpoint-175\n",
      "Configuration saved in ./t5/checkpoint-175/config.json\n",
      "Model weights saved in ./t5/checkpoint-175/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-175/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-175/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-175/spiece.model\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-350\n",
      "Configuration saved in ./t5/checkpoint-350/config.json\n",
      "Model weights saved in ./t5/checkpoint-350/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-350/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-350/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-350/spiece.model\n",
      "Saving model checkpoint to ./t5/checkpoint-525\n",
      "Configuration saved in ./t5/checkpoint-525/config.json\n",
      "Saving model checkpoint to ./t5/checkpoint-525\n",
      "Configuration saved in ./t5/checkpoint-525/config.json\n",
      "Model weights saved in ./t5/checkpoint-525/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-525/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-525/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-525/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-175] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-700\n",
      "Configuration saved in ./t5/checkpoint-700/config.json\n",
      "Model weights saved in ./t5/checkpoint-700/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-700/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-700/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-700/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-350] due to args.save_total_limit\n",
      "Saving model checkpoint to ./t5/checkpoint-875\n",
      "Configuration saved in ./t5/checkpoint-875/config.json\n",
      "Saving model checkpoint to ./t5/checkpoint-875\n",
      "Configuration saved in ./t5/checkpoint-875/config.json\n",
      "Model weights saved in ./t5/checkpoint-875/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-875/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-875/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-875/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-525] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-1050\n",
      "Saving model checkpoint to ./t5/checkpoint-1050\n",
      "Configuration saved in ./t5/checkpoint-1050/config.json\n",
      "Model weights saved in ./t5/checkpoint-1050/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-1050/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-1050/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-1050/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-700] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-1225\n",
      "Configuration saved in ./t5/checkpoint-1225/config.json\n",
      "Model weights saved in ./t5/checkpoint-1225/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-1225/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-1225/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-1225/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-875] due to args.save_total_limit\n",
      "Saving model checkpoint to ./t5/checkpoint-1400\n",
      "Configuration saved in ./t5/checkpoint-1400/config.json\n",
      "Saving model checkpoint to ./t5/checkpoint-1400\n",
      "Configuration saved in ./t5/checkpoint-1400/config.json\n",
      "Model weights saved in ./t5/checkpoint-1400/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-1400/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-1400/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-1400/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-1225] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-1575\n",
      "Configuration saved in ./t5/checkpoint-1575/config.json\n",
      "Saving model checkpoint to ./t5/checkpoint-1575\n",
      "Configuration saved in ./t5/checkpoint-1575/config.json\n",
      "Model weights saved in ./t5/checkpoint-1575/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-1575/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-1575/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-1575/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-1400] due to args.save_total_limit\n",
      "Saving model checkpoint to ./t5/checkpoint-1750\n",
      "Configuration saved in ./t5/checkpoint-1750/config.json\n",
      "Saving model checkpoint to ./t5/checkpoint-1750\n",
      "Configuration saved in ./t5/checkpoint-1750/config.json\n",
      "Model weights saved in ./t5/checkpoint-1750/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-1750/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-1750/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-1750/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-1575] due to args.save_total_limit\n",
      "Saving model checkpoint to ./t5/checkpoint-1925\n",
      "Configuration saved in ./t5/checkpoint-1925/config.json\n",
      "Saving model checkpoint to ./t5/checkpoint-1925\n",
      "Configuration saved in ./t5/checkpoint-1925/config.json\n",
      "Model weights saved in ./t5/checkpoint-1925/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-1925/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-1925/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-1925/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-1750] due to args.save_total_limit\n",
      "Saving model checkpoint to ./t5/checkpoint-2100\n",
      "Configuration saved in ./t5/checkpoint-2100/config.json\n",
      "Saving model checkpoint to ./t5/checkpoint-2100\n",
      "Configuration saved in ./t5/checkpoint-2100/config.json\n",
      "Model weights saved in ./t5/checkpoint-2100/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-2100/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-2100/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-2100/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-1925] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-2275\n",
      "Configuration saved in ./t5/checkpoint-2275/config.json\n",
      "Model weights saved in ./t5/checkpoint-2275/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-2275/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-2275/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-2275/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-2100] due to args.save_total_limit\n",
      "Saving model checkpoint to ./t5/checkpoint-2450\n",
      "Configuration saved in ./t5/checkpoint-2450/config.json\n",
      "Saving model checkpoint to ./t5/checkpoint-2450\n",
      "Configuration saved in ./t5/checkpoint-2450/config.json\n",
      "Model weights saved in ./t5/checkpoint-2450/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-2450/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-2450/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-2450/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-2275] due to args.save_total_limit\n",
      "Saving model checkpoint to ./t5/checkpoint-2625\n",
      "Saving model checkpoint to ./t5/checkpoint-2625\n",
      "Configuration saved in ./t5/checkpoint-2625/config.json\n",
      "Model weights saved in ./t5/checkpoint-2625/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-2625/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-2625/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-2625/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-2450] due to args.save_total_limit\n",
      "Saving model checkpoint to ./t5/checkpoint-2800\n",
      "Configuration saved in ./t5/checkpoint-2800/config.json\n",
      "Saving model checkpoint to ./t5/checkpoint-2800\n",
      "Configuration saved in ./t5/checkpoint-2800/config.json\n",
      "Model weights saved in ./t5/checkpoint-2800/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-2800/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-2800/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-2800/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-2625] due to args.save_total_limit\n",
      "Saving model checkpoint to ./t5/checkpoint-2975\n",
      "Saving model checkpoint to ./t5/checkpoint-2975\n",
      "Configuration saved in ./t5/checkpoint-2975/config.json\n",
      "Model weights saved in ./t5/checkpoint-2975/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-2975/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-2975/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-2975/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-2800] due to args.save_total_limit\n",
      "Saving model checkpoint to ./t5/checkpoint-3150\n",
      "Configuration saved in ./t5/checkpoint-3150/config.json\n",
      "Saving model checkpoint to ./t5/checkpoint-3150\n",
      "Configuration saved in ./t5/checkpoint-3150/config.json\n",
      "Model weights saved in ./t5/checkpoint-3150/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-3150/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-3150/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-3150/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-2975] due to args.save_total_limit\n",
      "Saving model checkpoint to ./t5/checkpoint-3325\n",
      "Configuration saved in ./t5/checkpoint-3325/config.json\n",
      "Saving model checkpoint to ./t5/checkpoint-3325\n",
      "Configuration saved in ./t5/checkpoint-3325/config.json\n",
      "Model weights saved in ./t5/checkpoint-3325/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-3325/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-3325/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-3325/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-3150] due to args.save_total_limit\n",
      "Saving model checkpoint to ./t5/checkpoint-3500\n",
      "Configuration saved in ./t5/checkpoint-3500/config.json\n",
      "Model weights saved in ./t5/checkpoint-3500/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-3500/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-3500/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-3500/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-3325] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./t5/checkpoint-1050 (score: 1.0).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3500, training_loss=0.021271900387746945, metrics={'train_runtime': 1659.1202, 'train_samples_per_second': 67.506, 'train_steps_per_second': 2.11, 'total_flos': 1.79832877056e+16, 'train_loss': 0.021271900387746945, 'epoch': 20.0})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_en = AutoModelForSeq2SeqLM.from_pretrained(\"t5-base\")\n",
    "model_en.to(device)\n",
    "trainer[\"wan\"][\"res15\"] = Seq2SeqTrainer(\n",
    "        model = model_en,\n",
    "        args = train_args,\n",
    "        tokenizer = tokenizer_en,\n",
    "        data_collator = data_collator_en,\n",
    "        train_dataset = wan_tok[\"res15\"][\"train\"],\n",
    "        eval_dataset = wan_tok[\"res15\"][\"val\"],\n",
    "        compute_metrics = lambda eval_preds: compute_metrics(eval_preds,decoding_args,tokenizer_en,wan_2[\"res15\"][\"val\"][\"task\"]),\n",
    "        preprocess_logits_for_metrics = preprocess_logits_for_metrics\n",
    "    )\n",
    "\n",
    "trainer[\"wan\"][\"res15\"].train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19it [00:10,  1.83it/s]\n"
     ]
    }
   ],
   "source": [
    "str_preds = generate_predictions(model_en, tokenizer_en, wan_tok[\"res15\"][\"test\"], device, 32, 512, decoding_args)\n",
    "preds = [catch_answer(el,\"asc\") for el in str_preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [catch_answer(el,\"asc\") for el in wan_2[\"res15\"][\"test\"][\"output\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recall': 0.4165680473372781,\n",
       " 'precision': 0.6037735849056604,\n",
       " 'f1_score': 0.49299719887955185}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_score(preds,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!rm -rf ./t5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numba_device = cuda.get_current_device()\n",
    "numba_device.reset()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wan Restaurant 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/m13519061/.cache/huggingface/hub/models--t5-base/snapshots/fe6d9bf207cd3337512ca838a8b453f87a9178ef/config.json\n",
      "Model config T5Config {\n",
      "  \"_name_or_path\": \"t5-base\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 3072,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/m13519061/.cache/huggingface/hub/models--t5-base/snapshots/fe6d9bf207cd3337512ca838a8b453f87a9178ef/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
      "\n",
      "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at t5-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n",
      "/home/m13519061/anaconda3/envs/absa/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 8540\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5340\n",
      "  Number of trainable parameters = 222903552\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='5340' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  19/5340 00:07 < 39:47, 2.23 it/s, Epoch 0.07/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 14\u001b[0m\n\u001b[1;32m      2\u001b[0m model_en\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      3\u001b[0m trainer[\u001b[39m\"\u001b[39m\u001b[39mwan\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mres16\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m Seq2SeqTrainer(\n\u001b[1;32m      4\u001b[0m         model \u001b[39m=\u001b[39m model_en,\n\u001b[1;32m      5\u001b[0m         args \u001b[39m=\u001b[39m train_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m         preprocess_logits_for_metrics \u001b[39m=\u001b[39m preprocess_logits_for_metrics\n\u001b[1;32m     12\u001b[0m     )\n\u001b[0;32m---> 14\u001b[0m trainer[\u001b[39m\"\u001b[39;49m\u001b[39mwan\u001b[39;49m\u001b[39m\"\u001b[39;49m][\u001b[39m\"\u001b[39;49m\u001b[39mres16\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[0;32m~/anaconda3/envs/absa/lib/python3.9/site-packages/transformers/trainer.py:1501\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n\u001b[1;32m   1498\u001b[0m inner_training_loop \u001b[39m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1499\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_training_loop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size, args\u001b[39m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1500\u001b[0m )\n\u001b[0;32m-> 1501\u001b[0m \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1502\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   1503\u001b[0m     resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   1504\u001b[0m     trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   1505\u001b[0m     ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   1506\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/absa/lib/python3.9/site-packages/transformers/trainer.py:1749\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1747\u001b[0m         tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   1748\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1749\u001b[0m     tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(model, inputs)\n\u001b[1;32m   1751\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   1752\u001b[0m     args\u001b[39m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1753\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1754\u001b[0m     \u001b[39mand\u001b[39;00m (torch\u001b[39m.\u001b[39misnan(tr_loss_step) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1755\u001b[0m ):\n\u001b[1;32m   1756\u001b[0m     \u001b[39m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1757\u001b[0m     tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/anaconda3/envs/absa/lib/python3.9/site-packages/transformers/trainer.py:2508\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2505\u001b[0m     \u001b[39mreturn\u001b[39;00m loss_mb\u001b[39m.\u001b[39mreduce_mean()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m   2507\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 2508\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_loss(model, inputs)\n\u001b[1;32m   2510\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mn_gpu \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   2511\u001b[0m     loss \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mmean()  \u001b[39m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/absa/lib/python3.9/site-packages/transformers/trainer.py:2540\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2538\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2539\u001b[0m     labels \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 2540\u001b[0m outputs \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minputs)\n\u001b[1;32m   2541\u001b[0m \u001b[39m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   2542\u001b[0m \u001b[39m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   2543\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mpast_index \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/absa/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/absa/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py:1648\u001b[0m, in \u001b[0;36mT5ForConditionalGeneration.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1645\u001b[0m         decoder_attention_mask \u001b[39m=\u001b[39m decoder_attention_mask\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder\u001b[39m.\u001b[39mfirst_device)\n\u001b[1;32m   1647\u001b[0m \u001b[39m# Decode\u001b[39;00m\n\u001b[0;32m-> 1648\u001b[0m decoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecoder(\n\u001b[1;32m   1649\u001b[0m     input_ids\u001b[39m=\u001b[39;49mdecoder_input_ids,\n\u001b[1;32m   1650\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mdecoder_attention_mask,\n\u001b[1;32m   1651\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49mdecoder_inputs_embeds,\n\u001b[1;32m   1652\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m   1653\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mhidden_states,\n\u001b[1;32m   1654\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1655\u001b[0m     head_mask\u001b[39m=\u001b[39;49mdecoder_head_mask,\n\u001b[1;32m   1656\u001b[0m     cross_attn_head_mask\u001b[39m=\u001b[39;49mcross_attn_head_mask,\n\u001b[1;32m   1657\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1658\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1659\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1660\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1661\u001b[0m )\n\u001b[1;32m   1663\u001b[0m sequence_output \u001b[39m=\u001b[39m decoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1665\u001b[0m \u001b[39m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/absa/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/absa/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py:1040\u001b[0m, in \u001b[0;36mT5Stack.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1027\u001b[0m     layer_outputs \u001b[39m=\u001b[39m checkpoint(\n\u001b[1;32m   1028\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m   1029\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1037\u001b[0m         \u001b[39mNone\u001b[39;00m,  \u001b[39m# past_key_value is always None with gradient checkpointing\u001b[39;00m\n\u001b[1;32m   1038\u001b[0m     )\n\u001b[1;32m   1039\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1040\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m   1041\u001b[0m         hidden_states,\n\u001b[1;32m   1042\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[1;32m   1043\u001b[0m         position_bias\u001b[39m=\u001b[39;49mposition_bias,\n\u001b[1;32m   1044\u001b[0m         encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m   1045\u001b[0m         encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[1;32m   1046\u001b[0m         encoder_decoder_position_bias\u001b[39m=\u001b[39;49mencoder_decoder_position_bias,\n\u001b[1;32m   1047\u001b[0m         layer_head_mask\u001b[39m=\u001b[39;49mlayer_head_mask,\n\u001b[1;32m   1048\u001b[0m         cross_attn_layer_head_mask\u001b[39m=\u001b[39;49mcross_attn_layer_head_mask,\n\u001b[1;32m   1049\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mpast_key_value,\n\u001b[1;32m   1050\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1051\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1052\u001b[0m     )\n\u001b[1;32m   1054\u001b[0m \u001b[39m# layer_outputs is a tuple with:\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m \u001b[39m# hidden-states, key-value-states, (self-attention position bias), (self-attention weights), (cross-attention position bias), (cross-attention weights)\u001b[39;00m\n\u001b[1;32m   1056\u001b[0m \u001b[39mif\u001b[39;00m use_cache \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/absa/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/absa/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py:699\u001b[0m, in \u001b[0;36mT5Block.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    697\u001b[0m     query_length \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 699\u001b[0m cross_attention_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayer[\u001b[39m1\u001b[39;49m](\n\u001b[1;32m    700\u001b[0m     hidden_states,\n\u001b[1;32m    701\u001b[0m     key_value_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m    702\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mencoder_attention_mask,\n\u001b[1;32m    703\u001b[0m     position_bias\u001b[39m=\u001b[39;49mencoder_decoder_position_bias,\n\u001b[1;32m    704\u001b[0m     layer_head_mask\u001b[39m=\u001b[39;49mcross_attn_layer_head_mask,\n\u001b[1;32m    705\u001b[0m     past_key_value\u001b[39m=\u001b[39;49mcross_attn_past_key_value,\n\u001b[1;32m    706\u001b[0m     query_length\u001b[39m=\u001b[39;49mquery_length,\n\u001b[1;32m    707\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    708\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    709\u001b[0m )\n\u001b[1;32m    710\u001b[0m hidden_states \u001b[39m=\u001b[39m cross_attention_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    712\u001b[0m \u001b[39m# clamp inf values to enable fp16 training\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/absa/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/absa/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py:613\u001b[0m, in \u001b[0;36mT5LayerCrossAttention.forward\u001b[0;34m(self, hidden_states, key_value_states, attention_mask, position_bias, layer_head_mask, past_key_value, use_cache, query_length, output_attentions)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    601\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    602\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    610\u001b[0m     output_attentions\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    611\u001b[0m ):\n\u001b[1;32m    612\u001b[0m     normed_hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer_norm(hidden_states)\n\u001b[0;32m--> 613\u001b[0m     attention_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mEncDecAttention(\n\u001b[1;32m    614\u001b[0m         normed_hidden_states,\n\u001b[1;32m    615\u001b[0m         mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    616\u001b[0m         key_value_states\u001b[39m=\u001b[39;49mkey_value_states,\n\u001b[1;32m    617\u001b[0m         position_bias\u001b[39m=\u001b[39;49mposition_bias,\n\u001b[1;32m    618\u001b[0m         layer_head_mask\u001b[39m=\u001b[39;49mlayer_head_mask,\n\u001b[1;32m    619\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mpast_key_value,\n\u001b[1;32m    620\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    621\u001b[0m         query_length\u001b[39m=\u001b[39;49mquery_length,\n\u001b[1;32m    622\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    623\u001b[0m     )\n\u001b[1;32m    624\u001b[0m     layer_output \u001b[39m=\u001b[39m hidden_states \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(attention_output[\u001b[39m0\u001b[39m])\n\u001b[1;32m    625\u001b[0m     outputs \u001b[39m=\u001b[39m (layer_output,) \u001b[39m+\u001b[39m attention_output[\u001b[39m1\u001b[39m:]  \u001b[39m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/absa/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/absa/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py:504\u001b[0m, in \u001b[0;36mT5Attention.forward\u001b[0;34m(self, hidden_states, mask, key_value_states, position_bias, past_key_value, layer_head_mask, query_length, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[39m# get key/value states\u001b[39;00m\n\u001b[1;32m    501\u001b[0m key_states \u001b[39m=\u001b[39m project(\n\u001b[1;32m    502\u001b[0m     hidden_states, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk, key_value_states, past_key_value[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m past_key_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    503\u001b[0m )\n\u001b[0;32m--> 504\u001b[0m value_states \u001b[39m=\u001b[39m project(\n\u001b[1;32m    505\u001b[0m     hidden_states, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mv, key_value_states, past_key_value[\u001b[39m1\u001b[39;49m] \u001b[39mif\u001b[39;49;00m past_key_value \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m\n\u001b[1;32m    506\u001b[0m )\n\u001b[1;32m    508\u001b[0m \u001b[39m# compute scores\u001b[39;00m\n\u001b[1;32m    509\u001b[0m scores \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmatmul(\n\u001b[1;32m    510\u001b[0m     query_states, key_states\u001b[39m.\u001b[39mtranspose(\u001b[39m3\u001b[39m, \u001b[39m2\u001b[39m)\n\u001b[1;32m    511\u001b[0m )  \u001b[39m# equivalent of torch.einsum(\"bnqd,bnkd->bnqk\", query_states, key_states), compatible with onnx op>9\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/absa/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py:485\u001b[0m, in \u001b[0;36mT5Attention.forward.<locals>.project\u001b[0;34m(hidden_states, proj_layer, key_value_states, past_key_value)\u001b[0m\n\u001b[1;32m    481\u001b[0m     hidden_states \u001b[39m=\u001b[39m shape(proj_layer(hidden_states))\n\u001b[1;32m    482\u001b[0m \u001b[39melif\u001b[39;00m past_key_value \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    483\u001b[0m     \u001b[39m# cross-attn\u001b[39;00m\n\u001b[1;32m    484\u001b[0m     \u001b[39m# (batch_size, n_heads, seq_length, dim_per_head)\u001b[39;00m\n\u001b[0;32m--> 485\u001b[0m     hidden_states \u001b[39m=\u001b[39m shape(proj_layer(key_value_states))\n\u001b[1;32m    487\u001b[0m \u001b[39mif\u001b[39;00m past_key_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    488\u001b[0m     \u001b[39mif\u001b[39;00m key_value_states \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    489\u001b[0m         \u001b[39m# self-attn\u001b[39;00m\n\u001b[1;32m    490\u001b[0m         \u001b[39m# (batch_size, n_heads, key_length, dim_per_head)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/absa/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/absa/lib/python3.9/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model_en = AutoModelForSeq2SeqLM.from_pretrained(\"t5-base\")\n",
    "model_en.to(device)\n",
    "trainer[\"wan\"][\"res16\"] = Seq2SeqTrainer(\n",
    "        model = model_en,\n",
    "        args = train_args,\n",
    "        tokenizer = tokenizer_en,\n",
    "        data_collator = data_collator_en,\n",
    "        train_dataset = wan_tok[\"res16\"][\"train\"],\n",
    "        eval_dataset = wan_tok[\"res16\"][\"val\"],\n",
    "        compute_metrics = lambda eval_preds: compute_metrics(eval_preds,decoding_args,tokenizer_en,wan_2[\"res16\"][\"val\"][\"task\"]),\n",
    "        preprocess_logits_for_metrics = preprocess_logits_for_metrics\n",
    "    )\n",
    "\n",
    "trainer[\"wan\"][\"res16\"].train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19it [00:10,  1.74it/s]\n"
     ]
    }
   ],
   "source": [
    "str_preds = generate_predictions(model_en, tokenizer_en, wan_tok[\"res16\"][\"test\"], device, 32, 512, decoding_args)\n",
    "preds = [catch_answer(el,\"asc\") for el in str_preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [catch_answer(el,\"asc\") for el in wan_2[\"res16\"][\"test\"][\"output\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recall': 0.027939464493597205,\n",
       " 'precision': 0.04411764705882353,\n",
       " 'f1_score': 0.03421240199572345}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_score(preds,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!rm -rf ./t5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numba_device = cuda.get_current_device()\n",
    "numba_device.reset()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zhang Restaurant 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/m13519061/.cache/huggingface/hub/models--t5-base/snapshots/fe6d9bf207cd3337512ca838a8b453f87a9178ef/config.json\n",
      "Model config T5Config {\n",
      "  \"_name_or_path\": \"t5-base\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 3072,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/m13519061/.cache/huggingface/hub/models--t5-base/snapshots/fe6d9bf207cd3337512ca838a8b453f87a9178ef/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
      "\n",
      "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at t5-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n",
      "/home/m13519061/anaconda3/envs/absa/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 5004\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3140\n",
      "  Number of trainable parameters = 222903552\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='3140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   2/3140 : < :, Epoch 0.01/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 31.75 GiB total capacity; 28.43 GiB already allocated; 21.94 MiB free; 29.92 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 14\u001b[0m\n\u001b[1;32m      2\u001b[0m model_en\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      3\u001b[0m trainer[\u001b[39m\"\u001b[39m\u001b[39mzhang\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mres15\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m Seq2SeqTrainer(\n\u001b[1;32m      4\u001b[0m         model \u001b[39m=\u001b[39m model_en,\n\u001b[1;32m      5\u001b[0m         args \u001b[39m=\u001b[39m train_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m         preprocess_logits_for_metrics \u001b[39m=\u001b[39m preprocess_logits_for_metrics\n\u001b[1;32m     12\u001b[0m     )\n\u001b[0;32m---> 14\u001b[0m trainer[\u001b[39m\"\u001b[39;49m\u001b[39mzhang\u001b[39;49m\u001b[39m\"\u001b[39;49m][\u001b[39m\"\u001b[39;49m\u001b[39mres15\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[0;32m~/anaconda3/envs/absa/lib/python3.9/site-packages/transformers/trainer.py:1501\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n\u001b[1;32m   1498\u001b[0m inner_training_loop \u001b[39m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1499\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_training_loop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size, args\u001b[39m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1500\u001b[0m )\n\u001b[0;32m-> 1501\u001b[0m \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1502\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   1503\u001b[0m     resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   1504\u001b[0m     trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   1505\u001b[0m     ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   1506\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/absa/lib/python3.9/site-packages/transformers/trainer.py:1749\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1747\u001b[0m         tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   1748\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1749\u001b[0m     tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(model, inputs)\n\u001b[1;32m   1751\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   1752\u001b[0m     args\u001b[39m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1753\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1754\u001b[0m     \u001b[39mand\u001b[39;00m (torch\u001b[39m.\u001b[39misnan(tr_loss_step) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1755\u001b[0m ):\n\u001b[1;32m   1756\u001b[0m     \u001b[39m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1757\u001b[0m     tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/anaconda3/envs/absa/lib/python3.9/site-packages/transformers/trainer.py:2508\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2505\u001b[0m     \u001b[39mreturn\u001b[39;00m loss_mb\u001b[39m.\u001b[39mreduce_mean()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m   2507\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 2508\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_loss(model, inputs)\n\u001b[1;32m   2510\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mn_gpu \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   2511\u001b[0m     loss \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mmean()  \u001b[39m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/absa/lib/python3.9/site-packages/transformers/trainer.py:2540\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2538\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2539\u001b[0m     labels \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 2540\u001b[0m outputs \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minputs)\n\u001b[1;32m   2541\u001b[0m \u001b[39m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   2542\u001b[0m \u001b[39m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   2543\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mpast_index \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/absa/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/absa/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py:1648\u001b[0m, in \u001b[0;36mT5ForConditionalGeneration.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1645\u001b[0m         decoder_attention_mask \u001b[39m=\u001b[39m decoder_attention_mask\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder\u001b[39m.\u001b[39mfirst_device)\n\u001b[1;32m   1647\u001b[0m \u001b[39m# Decode\u001b[39;00m\n\u001b[0;32m-> 1648\u001b[0m decoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecoder(\n\u001b[1;32m   1649\u001b[0m     input_ids\u001b[39m=\u001b[39;49mdecoder_input_ids,\n\u001b[1;32m   1650\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mdecoder_attention_mask,\n\u001b[1;32m   1651\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49mdecoder_inputs_embeds,\n\u001b[1;32m   1652\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m   1653\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mhidden_states,\n\u001b[1;32m   1654\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1655\u001b[0m     head_mask\u001b[39m=\u001b[39;49mdecoder_head_mask,\n\u001b[1;32m   1656\u001b[0m     cross_attn_head_mask\u001b[39m=\u001b[39;49mcross_attn_head_mask,\n\u001b[1;32m   1657\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1658\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1659\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1660\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1661\u001b[0m )\n\u001b[1;32m   1663\u001b[0m sequence_output \u001b[39m=\u001b[39m decoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1665\u001b[0m \u001b[39m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/absa/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/absa/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py:1040\u001b[0m, in \u001b[0;36mT5Stack.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1027\u001b[0m     layer_outputs \u001b[39m=\u001b[39m checkpoint(\n\u001b[1;32m   1028\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m   1029\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1037\u001b[0m         \u001b[39mNone\u001b[39;00m,  \u001b[39m# past_key_value is always None with gradient checkpointing\u001b[39;00m\n\u001b[1;32m   1038\u001b[0m     )\n\u001b[1;32m   1039\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1040\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m   1041\u001b[0m         hidden_states,\n\u001b[1;32m   1042\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[1;32m   1043\u001b[0m         position_bias\u001b[39m=\u001b[39;49mposition_bias,\n\u001b[1;32m   1044\u001b[0m         encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m   1045\u001b[0m         encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[1;32m   1046\u001b[0m         encoder_decoder_position_bias\u001b[39m=\u001b[39;49mencoder_decoder_position_bias,\n\u001b[1;32m   1047\u001b[0m         layer_head_mask\u001b[39m=\u001b[39;49mlayer_head_mask,\n\u001b[1;32m   1048\u001b[0m         cross_attn_layer_head_mask\u001b[39m=\u001b[39;49mcross_attn_layer_head_mask,\n\u001b[1;32m   1049\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mpast_key_value,\n\u001b[1;32m   1050\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1051\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1052\u001b[0m     )\n\u001b[1;32m   1054\u001b[0m \u001b[39m# layer_outputs is a tuple with:\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m \u001b[39m# hidden-states, key-value-states, (self-attention position bias), (self-attention weights), (cross-attention position bias), (cross-attention weights)\u001b[39;00m\n\u001b[1;32m   1056\u001b[0m \u001b[39mif\u001b[39;00m use_cache \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/absa/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/absa/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py:699\u001b[0m, in \u001b[0;36mT5Block.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    697\u001b[0m     query_length \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 699\u001b[0m cross_attention_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayer[\u001b[39m1\u001b[39;49m](\n\u001b[1;32m    700\u001b[0m     hidden_states,\n\u001b[1;32m    701\u001b[0m     key_value_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m    702\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mencoder_attention_mask,\n\u001b[1;32m    703\u001b[0m     position_bias\u001b[39m=\u001b[39;49mencoder_decoder_position_bias,\n\u001b[1;32m    704\u001b[0m     layer_head_mask\u001b[39m=\u001b[39;49mcross_attn_layer_head_mask,\n\u001b[1;32m    705\u001b[0m     past_key_value\u001b[39m=\u001b[39;49mcross_attn_past_key_value,\n\u001b[1;32m    706\u001b[0m     query_length\u001b[39m=\u001b[39;49mquery_length,\n\u001b[1;32m    707\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    708\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    709\u001b[0m )\n\u001b[1;32m    710\u001b[0m hidden_states \u001b[39m=\u001b[39m cross_attention_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    712\u001b[0m \u001b[39m# clamp inf values to enable fp16 training\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/absa/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/absa/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py:613\u001b[0m, in \u001b[0;36mT5LayerCrossAttention.forward\u001b[0;34m(self, hidden_states, key_value_states, attention_mask, position_bias, layer_head_mask, past_key_value, use_cache, query_length, output_attentions)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    601\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    602\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    610\u001b[0m     output_attentions\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    611\u001b[0m ):\n\u001b[1;32m    612\u001b[0m     normed_hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer_norm(hidden_states)\n\u001b[0;32m--> 613\u001b[0m     attention_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mEncDecAttention(\n\u001b[1;32m    614\u001b[0m         normed_hidden_states,\n\u001b[1;32m    615\u001b[0m         mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    616\u001b[0m         key_value_states\u001b[39m=\u001b[39;49mkey_value_states,\n\u001b[1;32m    617\u001b[0m         position_bias\u001b[39m=\u001b[39;49mposition_bias,\n\u001b[1;32m    618\u001b[0m         layer_head_mask\u001b[39m=\u001b[39;49mlayer_head_mask,\n\u001b[1;32m    619\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mpast_key_value,\n\u001b[1;32m    620\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    621\u001b[0m         query_length\u001b[39m=\u001b[39;49mquery_length,\n\u001b[1;32m    622\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    623\u001b[0m     )\n\u001b[1;32m    624\u001b[0m     layer_output \u001b[39m=\u001b[39m hidden_states \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(attention_output[\u001b[39m0\u001b[39m])\n\u001b[1;32m    625\u001b[0m     outputs \u001b[39m=\u001b[39m (layer_output,) \u001b[39m+\u001b[39m attention_output[\u001b[39m1\u001b[39m:]  \u001b[39m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/absa/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/absa/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py:501\u001b[0m, in \u001b[0;36mT5Attention.forward\u001b[0;34m(self, hidden_states, mask, key_value_states, position_bias, past_key_value, layer_head_mask, query_length, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    498\u001b[0m query_states \u001b[39m=\u001b[39m shape(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mq(hidden_states))  \u001b[39m# (batch_size, n_heads, seq_length, dim_per_head)\u001b[39;00m\n\u001b[1;32m    500\u001b[0m \u001b[39m# get key/value states\u001b[39;00m\n\u001b[0;32m--> 501\u001b[0m key_states \u001b[39m=\u001b[39m project(\n\u001b[1;32m    502\u001b[0m     hidden_states, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mk, key_value_states, past_key_value[\u001b[39m0\u001b[39;49m] \u001b[39mif\u001b[39;49;00m past_key_value \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m\n\u001b[1;32m    503\u001b[0m )\n\u001b[1;32m    504\u001b[0m value_states \u001b[39m=\u001b[39m project(\n\u001b[1;32m    505\u001b[0m     hidden_states, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mv, key_value_states, past_key_value[\u001b[39m1\u001b[39m] \u001b[39mif\u001b[39;00m past_key_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    506\u001b[0m )\n\u001b[1;32m    508\u001b[0m \u001b[39m# compute scores\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/absa/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py:485\u001b[0m, in \u001b[0;36mT5Attention.forward.<locals>.project\u001b[0;34m(hidden_states, proj_layer, key_value_states, past_key_value)\u001b[0m\n\u001b[1;32m    481\u001b[0m     hidden_states \u001b[39m=\u001b[39m shape(proj_layer(hidden_states))\n\u001b[1;32m    482\u001b[0m \u001b[39melif\u001b[39;00m past_key_value \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    483\u001b[0m     \u001b[39m# cross-attn\u001b[39;00m\n\u001b[1;32m    484\u001b[0m     \u001b[39m# (batch_size, n_heads, seq_length, dim_per_head)\u001b[39;00m\n\u001b[0;32m--> 485\u001b[0m     hidden_states \u001b[39m=\u001b[39m shape(proj_layer(key_value_states))\n\u001b[1;32m    487\u001b[0m \u001b[39mif\u001b[39;00m past_key_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    488\u001b[0m     \u001b[39mif\u001b[39;00m key_value_states \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    489\u001b[0m         \u001b[39m# self-attn\u001b[39;00m\n\u001b[1;32m    490\u001b[0m         \u001b[39m# (batch_size, n_heads, key_length, dim_per_head)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/absa/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/absa/lib/python3.9/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 31.75 GiB total capacity; 28.43 GiB already allocated; 21.94 MiB free; 29.92 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model_en = AutoModelForSeq2SeqLM.from_pretrained(\"t5-base\")\n",
    "model_en.to(device)\n",
    "trainer[\"zhang\"][\"res15\"] = Seq2SeqTrainer(\n",
    "        model = model_en,\n",
    "        args = train_args,\n",
    "        tokenizer = tokenizer_en,\n",
    "        data_collator = data_collator_en,\n",
    "        train_dataset = zhang_tok[\"res15\"][\"train\"],\n",
    "        eval_dataset = zhang_tok[\"res15\"][\"val\"],\n",
    "        compute_metrics = lambda eval_preds: compute_metrics(eval_preds,decoding_args,tokenizer_en,zhang_2[\"res15\"][\"val\"][\"task\"]),\n",
    "        preprocess_logits_for_metrics = preprocess_logits_for_metrics\n",
    "    )\n",
    "\n",
    "trainer[\"zhang\"][\"res15\"].train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [00:13,  1.19it/s]\n"
     ]
    }
   ],
   "source": [
    "str_preds = generate_predictions(model_en, tokenizer_en, zhang_tok[\"res15\"][\"test\"], device, 32, 512, decoding_args)\n",
    "preds = [catch_answer(el,\"oasc\") for el in str_preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [catch_answer(el,\"oasc\") for el in zhang_2[\"res15\"][\"test\"][\"output\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recall': 0.4305835010060362,\n",
       " 'precision': 0.7210084033613445,\n",
       " 'f1_score': 0.5391742012021976}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary_score(preds,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!rm -rf ./t5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numba_device = cuda.get_current_device()\n",
    "numba_device.reset()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zhang Restaurant 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/m13519061/.cache/huggingface/hub/models--t5-base/snapshots/fe6d9bf207cd3337512ca838a8b453f87a9178ef/config.json\n",
      "Model config T5Config {\n",
      "  \"_name_or_path\": \"t5-base\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 3072,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/m13519061/.cache/huggingface/hub/models--t5-base/snapshots/fe6d9bf207cd3337512ca838a8b453f87a9178ef/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
      "\n",
      "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at t5-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n",
      "/home/m13519061/anaconda3/envs/absa/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 5064\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3180\n",
      "  Number of trainable parameters = 222903552\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='60' max='3180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  60/3180 00:27 < 24:43, 2.10 it/s, Epoch 0.37/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 310\n",
      "  Batch size = 32\n",
      "  Num examples = 310\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-159\n",
      "Configuration saved in ./t5/checkpoint-159/config.json\n",
      "Model weights saved in ./t5/checkpoint-159/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-159/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-159/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-159/spiece.model\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 310\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-318\n",
      "Configuration saved in ./t5/checkpoint-318/config.json\n",
      "Model weights saved in ./t5/checkpoint-318/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-318/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-318/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-318/spiece.model\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 310\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-477\n",
      "Configuration saved in ./t5/checkpoint-477/config.json\n",
      "Model weights saved in ./t5/checkpoint-477/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-477/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-477/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-477/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-318] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 310\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-636\n",
      "Configuration saved in ./t5/checkpoint-636/config.json\n",
      "Model weights saved in ./t5/checkpoint-636/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-636/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-636/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-636/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-477] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 310\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-795\n",
      "Configuration saved in ./t5/checkpoint-795/config.json\n",
      "Model weights saved in ./t5/checkpoint-795/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-795/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-795/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-795/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-636] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 310\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-954\n",
      "Configuration saved in ./t5/checkpoint-954/config.json\n",
      "Model weights saved in ./t5/checkpoint-954/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-954/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-954/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-954/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-795] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 310\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-1113\n",
      "Configuration saved in ./t5/checkpoint-1113/config.json\n",
      "Model weights saved in ./t5/checkpoint-1113/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-1113/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-1113/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-1113/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-954] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 310\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-1272\n",
      "Configuration saved in ./t5/checkpoint-1272/config.json\n",
      "Model weights saved in ./t5/checkpoint-1272/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-1272/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-1272/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-1272/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-1113] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 310\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-1431\n",
      "Configuration saved in ./t5/checkpoint-1431/config.json\n",
      "Model weights saved in ./t5/checkpoint-1431/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-1431/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-1431/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-1431/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-159] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 310\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-1590\n",
      "Configuration saved in ./t5/checkpoint-1590/config.json\n",
      "Model weights saved in ./t5/checkpoint-1590/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-1590/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-1590/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-1590/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-1272] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 310\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-1749\n",
      "Configuration saved in ./t5/checkpoint-1749/config.json\n",
      "Model weights saved in ./t5/checkpoint-1749/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-1749/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-1749/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-1749/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-1590] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 310\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-1908\n",
      "Configuration saved in ./t5/checkpoint-1908/config.json\n",
      "Model weights saved in ./t5/checkpoint-1908/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-1908/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-1908/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-1908/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-1749] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 310\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-2067\n",
      "Configuration saved in ./t5/checkpoint-2067/config.json\n",
      "Model weights saved in ./t5/checkpoint-2067/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-2067/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-2067/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-2067/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-1908] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 310\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-2226\n",
      "Configuration saved in ./t5/checkpoint-2226/config.json\n",
      "Model weights saved in ./t5/checkpoint-2226/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-2226/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-2226/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-2226/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-1431] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 310\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-2385\n",
      "Configuration saved in ./t5/checkpoint-2385/config.json\n",
      "Model weights saved in ./t5/checkpoint-2385/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-2385/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-2385/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-2385/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-2067] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 310\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-2544\n",
      "Configuration saved in ./t5/checkpoint-2544/config.json\n",
      "Model weights saved in ./t5/checkpoint-2544/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-2544/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-2544/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-2544/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-2226] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 310\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-2703\n",
      "Configuration saved in ./t5/checkpoint-2703/config.json\n",
      "Model weights saved in ./t5/checkpoint-2703/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-2703/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-2703/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-2703/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-2385] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 310\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-2862\n",
      "Configuration saved in ./t5/checkpoint-2862/config.json\n",
      "Model weights saved in ./t5/checkpoint-2862/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-2862/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-2862/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-2862/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-2703] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 310\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-3021\n",
      "Configuration saved in ./t5/checkpoint-3021/config.json\n",
      "Model weights saved in ./t5/checkpoint-3021/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-3021/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-3021/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-3021/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-2862] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 310\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-3180\n",
      "Configuration saved in ./t5/checkpoint-3180/config.json\n",
      "Model weights saved in ./t5/checkpoint-3180/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-3180/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-3180/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-3180/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-3021] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./t5/checkpoint-2544 (score: 0.5271634002609127).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3180, training_loss=0.02443723297156628, metrics={'train_runtime': 1613.4167, 'train_samples_per_second': 62.774, 'train_steps_per_second': 1.971, 'total_flos': 1.397309066698752e+16, 'train_loss': 0.02443723297156628, 'epoch': 20.0})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_en = AutoModelForSeq2SeqLM.from_pretrained(\"t5-base\")\n",
    "model_en.to(device)\n",
    "trainer[\"zhang\"][\"res16\"] = Seq2SeqTrainer(\n",
    "        model = model_en,\n",
    "        args = train_args,\n",
    "        tokenizer = tokenizer_en,\n",
    "        data_collator = data_collator_en,\n",
    "        train_dataset = zhang_tok[\"res16\"][\"train\"],\n",
    "        eval_dataset = zhang_tok[\"res16\"][\"val\"],\n",
    "        compute_metrics = lambda eval_preds: compute_metrics(eval_preds,decoding_args,tokenizer_en,zhang_2[\"res16\"][\"val\"][\"task\"]),\n",
    "        preprocess_logits_for_metrics = preprocess_logits_for_metrics\n",
    "    )\n",
    "\n",
    "trainer[\"zhang\"][\"res16\"].train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [00:13,  1.19it/s]\n"
     ]
    }
   ],
   "source": [
    "str_preds = generate_predictions(model_en, tokenizer_en, zhang_tok[\"res16\"][\"test\"], device, 32, 512, decoding_args)\n",
    "preds = [catch_answer(el,\"oasc\") for el in str_preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [catch_answer(el,\"oasc\") for el in zhang_2[\"res16\"][\"test\"][\"output\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recall': 0.4305835010060362,\n",
       " 'precision': 0.7210084033613445,\n",
       " 'f1_score': 0.5391742012021976}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary_score(preds,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!rm -rf ./t5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numba_device = cuda.get_current_device()\n",
    "numba_device.reset()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# William Hotel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/m13519061/.cache/huggingface/hub/models--t5-base/snapshots/fe6d9bf207cd3337512ca838a8b453f87a9178ef/config.json\n",
      "Model config T5Config {\n",
      "  \"_name_or_path\": \"t5-base\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 3072,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/m13519061/.cache/huggingface/hub/models--t5-base/snapshots/fe6d9bf207cd3337512ca838a8b453f87a9178ef/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
      "\n",
      "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at t5-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n",
      "/home/m13519061/anaconda3/envs/absa/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 5064\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3180\n",
      "  Number of trainable parameters = 222903552\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='60' max='3180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  60/3180 00:27 < 24:43, 2.10 it/s, Epoch 0.37/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 310\n",
      "  Batch size = 32\n",
      "  Num examples = 310\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-159\n",
      "Configuration saved in ./t5/checkpoint-159/config.json\n",
      "Model weights saved in ./t5/checkpoint-159/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-159/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-159/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-159/spiece.model\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 310\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-318\n",
      "Configuration saved in ./t5/checkpoint-318/config.json\n",
      "Model weights saved in ./t5/checkpoint-318/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-318/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-318/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-318/spiece.model\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 310\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-477\n",
      "Configuration saved in ./t5/checkpoint-477/config.json\n",
      "Model weights saved in ./t5/checkpoint-477/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-477/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-477/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-477/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-318] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 310\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-636\n",
      "Configuration saved in ./t5/checkpoint-636/config.json\n",
      "Model weights saved in ./t5/checkpoint-636/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-636/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-636/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-636/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-477] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 310\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-795\n",
      "Configuration saved in ./t5/checkpoint-795/config.json\n",
      "Model weights saved in ./t5/checkpoint-795/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-795/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-795/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-795/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-636] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 310\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-954\n",
      "Configuration saved in ./t5/checkpoint-954/config.json\n",
      "Model weights saved in ./t5/checkpoint-954/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-954/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-954/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-954/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-795] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 310\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-1113\n",
      "Configuration saved in ./t5/checkpoint-1113/config.json\n",
      "Model weights saved in ./t5/checkpoint-1113/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-1113/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-1113/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-1113/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-954] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 310\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-1272\n",
      "Configuration saved in ./t5/checkpoint-1272/config.json\n",
      "Model weights saved in ./t5/checkpoint-1272/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-1272/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-1272/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-1272/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-1113] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 310\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-1431\n",
      "Configuration saved in ./t5/checkpoint-1431/config.json\n",
      "Model weights saved in ./t5/checkpoint-1431/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-1431/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-1431/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-1431/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-159] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 310\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-1590\n",
      "Configuration saved in ./t5/checkpoint-1590/config.json\n",
      "Model weights saved in ./t5/checkpoint-1590/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-1590/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-1590/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-1590/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-1272] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 310\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-1749\n",
      "Configuration saved in ./t5/checkpoint-1749/config.json\n",
      "Model weights saved in ./t5/checkpoint-1749/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-1749/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-1749/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-1749/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-1590] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 310\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-1908\n",
      "Configuration saved in ./t5/checkpoint-1908/config.json\n",
      "Model weights saved in ./t5/checkpoint-1908/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-1908/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-1908/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-1908/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-1749] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 310\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-2067\n",
      "Configuration saved in ./t5/checkpoint-2067/config.json\n",
      "Model weights saved in ./t5/checkpoint-2067/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-2067/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-2067/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-2067/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-1908] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 310\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-2226\n",
      "Configuration saved in ./t5/checkpoint-2226/config.json\n",
      "Model weights saved in ./t5/checkpoint-2226/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-2226/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-2226/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-2226/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-1431] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 310\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-2385\n",
      "Configuration saved in ./t5/checkpoint-2385/config.json\n",
      "Model weights saved in ./t5/checkpoint-2385/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-2385/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-2385/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-2385/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-2067] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 310\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-2544\n",
      "Configuration saved in ./t5/checkpoint-2544/config.json\n",
      "Model weights saved in ./t5/checkpoint-2544/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-2544/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-2544/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-2544/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-2226] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 310\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-2703\n",
      "Configuration saved in ./t5/checkpoint-2703/config.json\n",
      "Model weights saved in ./t5/checkpoint-2703/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-2703/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-2703/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-2703/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-2385] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 310\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-2862\n",
      "Configuration saved in ./t5/checkpoint-2862/config.json\n",
      "Model weights saved in ./t5/checkpoint-2862/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-2862/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-2862/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-2862/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-2703] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 310\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-3021\n",
      "Configuration saved in ./t5/checkpoint-3021/config.json\n",
      "Model weights saved in ./t5/checkpoint-3021/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-3021/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-3021/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-3021/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-2862] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 310\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./t5/checkpoint-3180\n",
      "Configuration saved in ./t5/checkpoint-3180/config.json\n",
      "Model weights saved in ./t5/checkpoint-3180/pytorch_model.bin\n",
      "tokenizer config file saved in ./t5/checkpoint-3180/tokenizer_config.json\n",
      "Special tokens file saved in ./t5/checkpoint-3180/special_tokens_map.json\n",
      "Copy vocab file to ./t5/checkpoint-3180/spiece.model\n",
      "Deleting older checkpoint [t5/checkpoint-3021] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./t5/checkpoint-2544 (score: 0.5271634002609127).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3180, training_loss=0.02443723297156628, metrics={'train_runtime': 1613.4167, 'train_samples_per_second': 62.774, 'train_steps_per_second': 1.971, 'total_flos': 1.397309066698752e+16, 'train_loss': 0.02443723297156628, 'epoch': 20.0})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = AutoModelForSeq2SeqLM.from_pretrained(\"Wikidepia/IndoT5-base\")\n",
    "model_en.to(device)\n",
    "trainer[\"william\"][\"hotel\"] = Seq2SeqTrainer(\n",
    "        model = model_id,\n",
    "        args = train_args,\n",
    "        tokenizer = tokenizer_id,\n",
    "        data_collator = data_collator_en,\n",
    "        train_dataset = william_tok[\"hotel\"][\"train\"],\n",
    "        eval_dataset = william_tok[\"hotel\"][\"val\"],\n",
    "        compute_metrics = lambda eval_preds: compute_metrics(eval_preds,decoding_args,tokenizer_en,william_2[\"hotel\"][\"val\"][\"task\"]),\n",
    "        preprocess_logits_for_metrics = preprocess_logits_for_metrics\n",
    "    )\n",
    "\n",
    "trainer[\"william\"][\"hotel\"].train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [00:13,  1.19it/s]\n"
     ]
    }
   ],
   "source": [
    "str_preds = generate_predictions(model_id, tokenizer_id, william_tok[\"hotel\"][\"test\"], device, 32, 512, decoding_args)\n",
    "preds = [catch_answer(el,\"oas\") for el in str_preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [catch_answer(el,\"oas\") for el in william_2[\"hotel\"][\"test\"][\"output\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recall': 0.4305835010060362,\n",
       " 'precision': 0.7210084033613445,\n",
       " 'f1_score': 0.5391742012021976}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary_score(preds,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!rm -rf ./t5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numba_device = cuda.get_current_device()\n",
    "numba_device.reset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "absa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
