{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../../src/\")\n",
    "import data_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "william_dir = dict(\n",
    "    hotel = \"../../../data/absa/id/william\"\n",
    ")\n",
    "\n",
    "william = dict(\n",
    "    hotel = dict(\n",
    "        train = data_utils.read_data(path=william_dir[\"hotel\"] + \"/train.txt\",\n",
    "                                     target_format=\"aos\"),\n",
    "        val = data_utils.read_data(path=william_dir[\"hotel\"] + \"/dev.txt\",\n",
    "                                     target_format=\"aos\"),\n",
    "        test = data_utils.read_data(path=william_dir[\"hotel\"] + \"/test.txt\",\n",
    "                                     target_format=\"aos\")\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "william[\"hotel\"][\"train\"] = [el for el in william[\"hotel\"][\"train\"] if len(el[\"target\"]) > 0]\n",
    "william[\"hotel\"][\"val\"] = [el for el in william[\"hotel\"][\"val\"] if len(el[\"target\"]) > 0]\n",
    "william[\"hotel\"][\"test\"] = [el for el in william[\"hotel\"][\"test\"] if len(el[\"target\"]) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = {\n",
    "    \"single\" : ['a', 'o'],\n",
    "    \"simple\" : [\"ao\", \"as\"],\n",
    "    \"complex\" : [\"aos\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "combination_tasks = [\n",
    "    tasks[\"simple\"],\n",
    "    tasks[\"complex\"],\n",
    "    tasks[\"single\"] + tasks[\"simple\"],\n",
    "    tasks[\"single\"] + tasks[\"complex\"],\n",
    "    tasks[\"simple\"] + tasks[\"complex\"],\n",
    "    tasks[\"single\"] + tasks[\"simple\"] + tasks[\"complex\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'o', 'ao', 'as', 'aos']\n"
     ]
    }
   ],
   "source": [
    "all_task = combination_tasks[-1]\n",
    "print(all_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "# William (AOS ID)\n",
    "william_intermediate = dict()\n",
    "\n",
    "for domain, v1 in william.items():\n",
    "    william_intermediate[domain] = dict()\n",
    "    for task in all_task:\n",
    "        william_intermediate[domain][task] = dict()\n",
    "        for split in v1.keys():\n",
    "            ds = william[domain][split]\n",
    "            ds_copy = deepcopy(ds)\n",
    "            for i in range(len(ds_copy)):\n",
    "                # Reduce\n",
    "                ds_copy[i][\"target\"] = data_utils.reduce_targets(ds_copy[i][\"target\"],task)\n",
    "                # Remove Duplicates\n",
    "                ds_copy[i][\"target\"] = data_utils.remove_duplicate_targets(ds_copy[i][\"target\"])\n",
    "            william_intermediate[domain][task][split] = ds_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = \"<extra_id_X>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_answer(targets,se_order):\n",
    "    if len(targets) == 0:\n",
    "        return \"NULL\"\n",
    "    result = []\n",
    "    counter = 0\n",
    "    for t in targets:\n",
    "        constructed_t = \"\"\n",
    "        for se in se_order:\n",
    "            counter = counter % 100\n",
    "            constructed_t += ' ' + mask.replace('X',str(counter)) + ' ' + t[data_utils.SENTIMENT_ELEMENT[se]]\n",
    "            counter += 1\n",
    "        constructed_t = constructed_t.strip()\n",
    "        result.append(constructed_t)\n",
    "    result = \" ; \".join(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def construct_prompt(text,se_order):\n",
    "#     pattern = []\n",
    "#     for counter, se in enumerate(se_order):\n",
    "#         pattern.append(data_utils.SENTIMENT_ELEMENT[se] + \" : \" + mask.replace('X',str(counter)))\n",
    "#     pattern = \" ,\".join(pattern)\n",
    "#     prompt = f\"Ekstrak dengan format >> {pattern} | \"\n",
    "#     # result = text + \"| \" + pattern\n",
    "#     result = prompt + text\n",
    "#     return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def catch_answer(output,se_order):\n",
    "    if output == \"NULL\":\n",
    "        return []\n",
    "    output = output.replace(\"<pad>\",'')\n",
    "    output = output.replace(\"</s>\",'')\n",
    "    pattern = r\"\"\n",
    "    for se in se_order:\n",
    "        if se != 's':\n",
    "            pattern += f\"<extra_id_\\d+>\\s*(?P<{data_utils.SENTIMENT_ELEMENT[se]}>[^;]+)\\s*\"\n",
    "        else:\n",
    "            pattern += f\"<extra_id_\\d+>\\s*(?P<{data_utils.SENTIMENT_ELEMENT['s']}>positive|negative|neutral)\\s*\"\n",
    "    found = [found_iter.groupdict() for found_iter in re.finditer(pattern,output)]\n",
    "    for i in range(len(found)):\n",
    "        for k, v in found[i].items():\n",
    "            found[i][k] = found[i][k].strip()\n",
    "    return found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "william_2 = dict()\n",
    "for domain, v1 in william_intermediate.items():\n",
    "    william_2[domain] = {\n",
    "        \"train\" : [], # basic task\n",
    "        \"val\" : [], # complex task\n",
    "        \"test\" : [] # complex task\n",
    "    }\n",
    "    # TRAIN\n",
    "    for basic_task in all_task:\n",
    "        for el in william_intermediate[domain][basic_task][\"train\"]:\n",
    "            william_2[domain][\"train\"].append({\n",
    "                    \"input\" : el[\"text\"],#construct_prompt(el[\"text\"],basic_task),\n",
    "                    \"output\" : construct_answer(el[\"target\"],basic_task),\n",
    "                    \"task\" : basic_task\n",
    "                })\n",
    "    # VAL\n",
    "    for basic_task in all_task:\n",
    "        for el in william_intermediate[domain][\"aos\"][\"val\"]:\n",
    "            william_2[domain][\"val\"].append({\n",
    "                    \"input\" : el[\"text\"],#construct_prompt(el[\"text\"],\"aos\"),\n",
    "                    \"output\" : construct_answer(el[\"target\"],basic_task),\n",
    "                    \"task\" : basic_task\n",
    "                })\n",
    "    # TEST\n",
    "    for basic_task in all_task:\n",
    "        for el in william_intermediate[domain][\"aos\"][\"test\"]:\n",
    "            william_2[domain][\"test\"].append({\n",
    "                    \"input\" : el[\"text\"],#construct_prompt(el[\"text\"],\"aos\"),\n",
    "                    \"output\" : construct_answer(el[\"target\"],basic_task),\n",
    "                    \"task\" : basic_task\n",
    "                })\n",
    "    william_2[domain][\"train\"] = Dataset.from_list(william_2[domain][\"train\"])\n",
    "    william_2[domain][\"val\"] = Dataset.from_list(william_2[domain][\"val\"])\n",
    "    william_2[domain][\"test\"] = Dataset.from_list(william_2[domain][\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "william_2[\"hotel\"] = DatasetDict(william_2[\"hotel\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input', 'output', 'task'],\n",
       "        num_rows: 14180\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['input', 'output', 'task'],\n",
       "        num_rows: 4675\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input', 'output', 'task'],\n",
       "        num_rows: 4840\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "william_2[\"hotel\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_entailment_dataset(row):\n",
    "    return {\n",
    "        \"sentence_A\" : row[\"input\"],\n",
    "        \"sentence_B\" : row[\"output\"],\n",
    "        \"label\" : row[\"task\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'kamar saya ada kendala di ac tidak berfungsi optimal . dan juga wifi koneksi kurang stabil .',\n",
       " 'output': '<extra_id_0> ac ; <extra_id_1> wifi koneksi',\n",
       " 'task': 'a'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "william_2[\"hotel\"][\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    }
   ],
   "source": [
    "william_2[\"hotel\"] = william_2[\"hotel\"].map(create_entailment_dataset,remove_columns=[\"input\",\"output\",\"task\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence_A': 'pelayanan yang baik .',\n",
       " 'sentence_B': '<extra_id_0> pelayanan <extra_id_1> baik <extra_id_2> positive',\n",
       " 'label': 'aos'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "william_2[\"hotel\"][\"val\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample = william_2[\"hotel\"][\"train\"].shuffle()\n",
    "val_sample = william_2[\"hotel\"][\"val\"].shuffle()\n",
    "test_sample = william_2[\"hotel\"][\"test\"].shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample = train_sample.select(range(500))\n",
    "val_sample = val_sample.select(range(300))\n",
    "test_sample = test_sample.select(range(200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating CSV from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 122.38ba/s]\n",
      "Creating CSV from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 192.42ba/s]\n",
      "Creating CSV from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 241.14ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "44528"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample.to_csv(\"hotel_entailment_train_500.tsv\",sep=\"\\t\")\n",
    "val_sample.to_csv(\"hotel_entailment_val_300.tsv\",sep=\"\\t\")\n",
    "test_sample.to_csv(\"hotel_entailment_test_200.tsv\",sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating CSV from Arrow format: 100%|██████████| 15/15 [00:00<00:00, 72.22ba/s]\n",
      "Creating CSV from Arrow format: 100%|██████████| 5/5 [00:00<00:00, 130.33ba/s]\n",
      "Creating CSV from Arrow format: 100%|██████████| 5/5 [00:00<00:00, 106.47ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "999337"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "william_2[\"hotel\"][\"train\"].to_csv(\"hotel_entailment_train.tsv\",sep=\"\\t\")\n",
    "william_2[\"hotel\"][\"val\"].to_csv(\"hotel_entailment_val.tsv\",sep=\"\\t\")\n",
    "william_2[\"hotel\"][\"test\"].to_csv(\"hotel_entailment_test.tsv\",sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sentence_A', 'sentence_B', 'label'],\n",
       "    num_rows: 14180\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "william_2[\"hotel\"][\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "absa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
