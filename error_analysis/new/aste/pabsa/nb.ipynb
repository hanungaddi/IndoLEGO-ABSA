{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import T5Tokenizer\n",
    "\n",
    "model_name_or_path = \"/srv/nas_data1/text/randy/absa/models/facebook_research/generative/fix/t5/t5_pabsa_S256_wid_small_blank=1.0\"\n",
    "train_path = \"./train.csv\"\n",
    "prediction_news_path = \"./news/prediction.csv\"\n",
    "prediction_socmed_path = \"./socmed/prediction.csv\"\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name_or_path)\n",
    "train = pd.read_csv(train_path)\n",
    "pred_news = pd.read_csv(prediction_news_path)\n",
    "pred_socmed = pd.read_csv(prediction_socmed_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_aste = train.loc[train.task == \"aste\"].copy()\n",
    "train_aste = train_aste[[\"text\",\"target\",\"input\",\"prompt\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_news = pred_news[[\"prompt\",\"text\",\"target\",\"string_preds\",\"raw_prediction\"]]\n",
    "pred_socmed = pred_socmed[[\"prompt\",\"text\",\"target\",\"string_preds\",\"raw_prediction\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = tokenizer.get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def len_input(text):\n",
    "    return len(tokenizer.encode(text))\n",
    "\n",
    "def oov_percentage(text):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    n = 0\n",
    "    for t in tokens:\n",
    "        if t not in vocab:\n",
    "            n += 1\n",
    "    return n/len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_aste[\"n_token\"] = train_aste.input.apply(len_input)\n",
    "train_aste[\"oov\"] = train_aste.input.apply(oov_percentage)\n",
    "\n",
    "pred_news[\"n_token\"] = pred_news.apply(lambda x : len_input(x[\"prompt\"] + \" \" + x[\"text\"]),axis=1)\n",
    "pred_news[\"oov\"] = pred_news.apply(lambda x : oov_percentage(x[\"prompt\"] + \" \" + x[\"text\"]),axis=1)\n",
    "\n",
    "pred_socmed[\"n_token\"] = pred_socmed.apply(lambda x : len_input(x[\"prompt\"] + \" \" + x[\"text\"]),axis=1)\n",
    "pred_socmed[\"oov\"] = pred_socmed.apply(lambda x : oov_percentage(x[\"prompt\"] + \" \" + x[\"text\"]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "str_pattern = r'\\(\\s?(.+)\\s?,\\s?(.+)\\s?,\\s?(positive|negative|neutral)\\s?\\)'\n",
    "\n",
    "mono = str_pattern\n",
    "multiple = f\"{str_pattern}\\s?;?\\s?({str_pattern})+\"\n",
    "mono_pattern = re.compile(mono)\n",
    "multiple_pattern = re.compile(multiple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_generation(text):\n",
    "    if text.strip() == \"NONE\":\n",
    "        return True\n",
    "    if mono_pattern.match(text) or multiple_pattern.match(text):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_news[\"valid_generation\"] = pred_news.string_preds.apply(is_valid_generation)\n",
    "pred_socmed[\"valid_generation\"] = pred_socmed.string_preds.apply(is_valid_generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>string_preds</th>\n",
       "      <th>raw_prediction</th>\n",
       "      <th>n_token</th>\n",
       "      <th>oov</th>\n",
       "      <th>valid_generation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ekstraksi triplet aste :</td>\n",
       "      <td>Terakhir , masyarakat sendiri akan memperoleh ...</td>\n",
       "      <td>[{'aspect': 'saham', 'opinion': 'memperoleh', ...</td>\n",
       "      <td>NONE</td>\n",
       "      <td>[]</td>\n",
       "      <td>35</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ekstraksi triplet aste :</td>\n",
       "      <td>Sementara itu , konser BTS Permission to Dance...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NONE</td>\n",
       "      <td>[]</td>\n",
       "      <td>30</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ekstraksi triplet aste :</td>\n",
       "      <td>Ketika koneksi internet di rumah tidak stabil ...</td>\n",
       "      <td>[{'aspect': 'koneksi internet', 'opinion': 'ti...</td>\n",
       "      <td>NONE</td>\n",
       "      <td>[]</td>\n",
       "      <td>32</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ekstraksi triplet aste :</td>\n",
       "      <td>Di sisi lain , Indonesia kaya akan sumber daya...</td>\n",
       "      <td>[{'aspect': 'Indonesia', 'opinion': 'kaya akan...</td>\n",
       "      <td>( Indonesia, kaya, positive ) ; ( sumber daya ...</td>\n",
       "      <td>[{'aspect': 'sumber daya gas alam', 'opinion':...</td>\n",
       "      <td>30</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ekstraksi triplet aste :</td>\n",
       "      <td>Agensi yang menaungi BTS , Big Hit Music , men...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NONE</td>\n",
       "      <td>[]</td>\n",
       "      <td>45</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>ekstraksi triplet aste :</td>\n",
       "      <td>Arti nya , segala hal yang dianggap terstruktu...</td>\n",
       "      <td>[{'aspect': 'segala hal yang dianggap terstruk...</td>\n",
       "      <td>NONE</td>\n",
       "      <td>[]</td>\n",
       "      <td>32</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>ekstraksi triplet aste :</td>\n",
       "      <td>\" Inflasi adalah ' ledakan ' Big Bang , \" kata...</td>\n",
       "      <td>[]</td>\n",
       "      <td>( Inflasi, ledakan'Big Bang, negative )</td>\n",
       "      <td>[{'aspect': 'Inflasi', 'opinion': \"ledakan'Big...</td>\n",
       "      <td>33</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>ekstraksi triplet aste :</td>\n",
       "      <td>Jin melanjutkan , tidak peduli lelah fisik mau...</td>\n",
       "      <td>[{'aspect': 'perusahaan', 'opinion': 'tetap se...</td>\n",
       "      <td>( ARMY, tetap senang, positive ) ; ( ARMY, bah...</td>\n",
       "      <td>[{'aspect': 'ARMY', 'opinion': 'tetap senang',...</td>\n",
       "      <td>38</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>ekstraksi triplet aste :</td>\n",
       "      <td>Kini jumlah kasus Covid - 19 secara keseluruha...</td>\n",
       "      <td>[{'aspect': 'konser', 'opinion': 'berisi penuh...</td>\n",
       "      <td>NONE</td>\n",
       "      <td>[]</td>\n",
       "      <td>54</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>ekstraksi triplet aste :</td>\n",
       "      <td>Halaman 3 &gt;&gt;&gt;</td>\n",
       "      <td>[]</td>\n",
       "      <td>NONE</td>\n",
       "      <td>[]</td>\n",
       "      <td>13</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>455 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       prompt  \\\n",
       "0    ekstraksi triplet aste :   \n",
       "1    ekstraksi triplet aste :   \n",
       "2    ekstraksi triplet aste :   \n",
       "3    ekstraksi triplet aste :   \n",
       "4    ekstraksi triplet aste :   \n",
       "..                        ...   \n",
       "450  ekstraksi triplet aste :   \n",
       "451  ekstraksi triplet aste :   \n",
       "452  ekstraksi triplet aste :   \n",
       "453  ekstraksi triplet aste :   \n",
       "454  ekstraksi triplet aste :   \n",
       "\n",
       "                                                  text  \\\n",
       "0    Terakhir , masyarakat sendiri akan memperoleh ...   \n",
       "1    Sementara itu , konser BTS Permission to Dance...   \n",
       "2    Ketika koneksi internet di rumah tidak stabil ...   \n",
       "3    Di sisi lain , Indonesia kaya akan sumber daya...   \n",
       "4    Agensi yang menaungi BTS , Big Hit Music , men...   \n",
       "..                                                 ...   \n",
       "450  Arti nya , segala hal yang dianggap terstruktu...   \n",
       "451  \" Inflasi adalah ' ledakan ' Big Bang , \" kata...   \n",
       "452  Jin melanjutkan , tidak peduli lelah fisik mau...   \n",
       "453  Kini jumlah kasus Covid - 19 secara keseluruha...   \n",
       "454                                      Halaman 3 >>>   \n",
       "\n",
       "                                                target  \\\n",
       "0    [{'aspect': 'saham', 'opinion': 'memperoleh', ...   \n",
       "1                                                   []   \n",
       "2    [{'aspect': 'koneksi internet', 'opinion': 'ti...   \n",
       "3    [{'aspect': 'Indonesia', 'opinion': 'kaya akan...   \n",
       "4                                                   []   \n",
       "..                                                 ...   \n",
       "450  [{'aspect': 'segala hal yang dianggap terstruk...   \n",
       "451                                                 []   \n",
       "452  [{'aspect': 'perusahaan', 'opinion': 'tetap se...   \n",
       "453  [{'aspect': 'konser', 'opinion': 'berisi penuh...   \n",
       "454                                                 []   \n",
       "\n",
       "                                          string_preds  \\\n",
       "0                                                 NONE   \n",
       "1                                                 NONE   \n",
       "2                                                 NONE   \n",
       "3    ( Indonesia, kaya, positive ) ; ( sumber daya ...   \n",
       "4                                                 NONE   \n",
       "..                                                 ...   \n",
       "450                                               NONE   \n",
       "451            ( Inflasi, ledakan'Big Bang, negative )   \n",
       "452  ( ARMY, tetap senang, positive ) ; ( ARMY, bah...   \n",
       "453                                               NONE   \n",
       "454                                               NONE   \n",
       "\n",
       "                                        raw_prediction  n_token       oov  \\\n",
       "0                                                   []       35  0.000000   \n",
       "1                                                   []       30  0.000000   \n",
       "2                                                   []       32  0.000000   \n",
       "3    [{'aspect': 'sumber daya gas alam', 'opinion':...       30  0.000000   \n",
       "4                                                   []       45  0.000000   \n",
       "..                                                 ...      ...       ...   \n",
       "450                                                 []       32  0.000000   \n",
       "451  [{'aspect': 'Inflasi', 'opinion': \"ledakan'Big...       33  0.000000   \n",
       "452  [{'aspect': 'ARMY', 'opinion': 'tetap senang',...       38  0.000000   \n",
       "453                                                 []       54  0.000000   \n",
       "454                                                 []       13  0.083333   \n",
       "\n",
       "     valid_generation  \n",
       "0                True  \n",
       "1                True  \n",
       "2                True  \n",
       "3                True  \n",
       "4                True  \n",
       "..                ...  \n",
       "450              True  \n",
       "451              True  \n",
       "452              True  \n",
       "453              True  \n",
       "454              True  \n",
       "\n",
       "[455 rows x 8 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_aste = train_aste[[\"text\",\"target\",\"n_token\",\"oov\"]]\n",
    "pred_news = pred_news[[\"text\",\"target\",\"string_preds\",\"raw_prediction\",\"n_token\",\"oov\",\"valid_generation\"]]\n",
    "pred_socmed = pred_socmed[[\"text\",\"target\",\"string_preds\",\"raw_prediction\",\"n_token\",\"oov\",\"valid_generation\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_aste.to_csv(\"train_aste.csv\",index=False)\n",
    "pred_news.to_csv(\"pred_news.csv\",index=False)\n",
    "pred_socmed.to_csv(\"pred_socmed.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_type(row):\n",
    "    target = row[\"target\"]\n",
    "    raw_prediction = row[\"raw_prediction\"]\n",
    "    if target != \"[]\" and raw_prediction == \"[]\":\n",
    "        return 0\n",
    "    if target == \"[]\" and raw_prediction != \"[]\":\n",
    "        return 1\n",
    "    return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique(list_of_dictionary):\n",
    "    res = []\n",
    "    for el in list_of_dictionary:\n",
    "        if el not in res:\n",
    "            res.append(el)\n",
    "    return res\n",
    "\n",
    "def is_equal(row):\n",
    "    target = eval(row[\"target\"])\n",
    "    raw_prediction = unique(eval(row[\"raw_prediction\"]))\n",
    "\n",
    "    if len(target) != len(raw_prediction):\n",
    "        return False\n",
    "    \n",
    "    for t in target:\n",
    "        if t not in raw_prediction:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_false_pred_news = pred_news.loc[~pred_news.apply(is_equal,axis=1)].copy()\n",
    "sample_false_pred_socmed = pred_socmed.loc[~pred_socmed.apply(is_equal,axis=1)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_false_pred_news[\"error_type\"] = sample_false_pred_news.apply(error_type,axis=1)\n",
    "sample_false_pred_socmed[\"error_type\"] = sample_false_pred_socmed.apply(error_type,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_false_pred_news = sample_false_pred_news.sort_values(by=\"error_type\")\n",
    "sample_false_pred_socmed = sample_false_pred_socmed.sort_values(by=\"error_type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_false_pred_news = pd.concat([\n",
    "    sample_false_pred_news.loc[sample_false_pred_news.error_type == 0].sample(5,random_state=42),\n",
    "    sample_false_pred_news.loc[sample_false_pred_news.error_type == 1].sample(5,random_state=42),\n",
    "    sample_false_pred_news.loc[sample_false_pred_news.error_type == 2].sample(5,random_state=42)\n",
    "])\n",
    "\n",
    "sample_false_pred_socmed = pd.concat([\n",
    "    sample_false_pred_socmed.loc[sample_false_pred_socmed.error_type == 0].sample(5,random_state=42),\n",
    "    sample_false_pred_socmed.loc[sample_false_pred_socmed.error_type == 1].sample(5,random_state=42),\n",
    "    sample_false_pred_socmed.loc[sample_false_pred_socmed.error_type == 2].sample(5,random_state=42)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_false_pred_news = sample_false_pred_news[sample_false_pred_news.columns[:-1]]\n",
    "sample_false_pred_socmed = sample_false_pred_socmed[sample_false_pred_socmed.columns[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_false_pred_news.to_csv(\"./analysis/sample_false_pred_news.csv\",index=False)\n",
    "sample_false_pred_socmed.to_csv(\"./analysis/sample_false_pred_socmed.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('absa')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5b39f2579f8b6cd4576fdc137fdffaab644b0ca009c2f95d260a904125131941"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
